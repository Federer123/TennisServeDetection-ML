{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd0wgQTvv5xw",
        "outputId": "50d9e49f-fd5d-4ab0-a542-f6a6afa8965b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JjZNBo5FuvEj"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def read_csv(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        for row in reader:\n",
        "            data.append(row)\n",
        "    return data\n",
        "\n",
        "def process_data(rectangle_data, point_data):\n",
        "    processed_data = defaultdict(lambda: {'bboxes': [], 'keypoints': []})\n",
        "\n",
        "    for rectangle_entry in rectangle_data:\n",
        "        image_name = rectangle_entry[5]\n",
        "        bbox_info = {\n",
        "            'label_name': rectangle_entry[0],\n",
        "            'bbox_x': rectangle_entry[1],\n",
        "            'bbox_y': rectangle_entry[2],\n",
        "            'bbox_width': rectangle_entry[3],\n",
        "            'bbox_height': rectangle_entry[4]\n",
        "        }\n",
        "        processed_data[image_name]['bboxes'].append(bbox_info)\n",
        "\n",
        "    for point_entry in point_data:\n",
        "        image_name = point_entry[3]\n",
        "        keypoint_info = {\n",
        "            'label_name': point_entry[0],\n",
        "            'x': point_entry[1],\n",
        "            'y': point_entry[2]\n",
        "        }\n",
        "        processed_data[image_name]['keypoints'].append(keypoint_info)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "def generate_json_files(processed_data):\n",
        "    for image_name, data in processed_data.items():\n",
        "        with open(f'/content/drive/MyDrive/TennisMLProject/{image_name.split(\".\")[0]}.json', 'w') as jsonfile:\n",
        "            json.dump(data, jsonfile, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NNuPQjiSvBqK"
      },
      "outputs": [],
      "source": [
        "rectangle_data = read_csv('Rectangle.csv')\n",
        "point_data = read_csv('Point.csv')\n",
        "processed_data = process_data(rectangle_data, point_data)\n",
        "generate_json_files(processed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JdnFN3Dn4iW7"
      },
      "outputs": [],
      "source": [
        "import os, cv2, numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "import albumentations as A # Library for augmentations\n",
        "\n",
        "import math\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision.models.detection.mask_rcnn\n",
        "#from coco_eval import CocoEvaluator\n",
        "#from coco_utils import get_coco_api_from_dataset\n",
        "\n",
        "import copy\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "import numpy as np\n",
        "import pycocotools.mask as mask_util\n",
        "import torch\n",
        "#import utils\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "import datetime\n",
        "import errno\n",
        "import os\n",
        "import time\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "\n",
        "from pycocotools import mask as coco_mask\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, Tensor\n",
        "from torchvision import ops\n",
        "from torchvision.transforms import functional as F, InterpolationMode, transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LsJGUfTCgqjE"
      },
      "outputs": [],
      "source": [
        "def _flip_coco_person_keypoints(kps, width):\n",
        "    flip_inds = [0, 2, 1, 4, 3, 6, 5, 8, 7, 10, 9, 12, 11, 14, 13, 16, 15]\n",
        "    flipped_data = kps[:, flip_inds]\n",
        "    flipped_data[..., 0] = width - flipped_data[..., 0]\n",
        "    # Maintain COCO convention that if visibility == 0, then x, y = 0\n",
        "    inds = flipped_data[..., 2] == 0\n",
        "    flipped_data[inds] = 0\n",
        "    return flipped_data\n",
        "\n",
        "\n",
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class RandomHorizontalFlip(T.RandomHorizontalFlip):\n",
        "    def forward(\n",
        "        self, image: Tensor, target: Optional[Dict[str, Tensor]] = None\n",
        "    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:\n",
        "        if torch.rand(1) < self.p:\n",
        "            image = F.hflip(image)\n",
        "            if target is not None:\n",
        "                _, _, width = F.get_dimensions(image)\n",
        "                target[\"boxes\"][:, [0, 2]] = width - target[\"boxes\"][:, [2, 0]]\n",
        "                if \"masks\" in target:\n",
        "                    target[\"masks\"] = target[\"masks\"].flip(-1)\n",
        "                if \"keypoints\" in target:\n",
        "                    keypoints = target[\"keypoints\"]\n",
        "                    keypoints = _flip_coco_person_keypoints(keypoints, width)\n",
        "                    target[\"keypoints\"] = keypoints\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class PILToTensor(nn.Module):\n",
        "    def forward(\n",
        "        self, image: Tensor, target: Optional[Dict[str, Tensor]] = None\n",
        "    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:\n",
        "        image = F.pil_to_tensor(image)\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class ToDtype(nn.Module):\n",
        "    def __init__(self, dtype: torch.dtype, scale: bool = False) -> None:\n",
        "        super().__init__()\n",
        "        self.dtype = dtype\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(\n",
        "        self, image: Tensor, target: Optional[Dict[str, Tensor]] = None\n",
        "    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:\n",
        "        if not self.scale:\n",
        "            return image.to(dtype=self.dtype), target\n",
        "        image = F.convert_image_dtype(image, self.dtype)\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class RandomIoUCrop(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        min_scale: float = 0.3,\n",
        "        max_scale: float = 1.0,\n",
        "        min_aspect_ratio: float = 0.5,\n",
        "        max_aspect_ratio: float = 2.0,\n",
        "        sampler_options: Optional[List[float]] = None,\n",
        "        trials: int = 40,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # Configuration similar to https://github.com/weiliu89/caffe/blob/ssd/examples/ssd/ssd_coco.py#L89-L174\n",
        "        self.min_scale = min_scale\n",
        "        self.max_scale = max_scale\n",
        "        self.min_aspect_ratio = min_aspect_ratio\n",
        "        self.max_aspect_ratio = max_aspect_ratio\n",
        "        if sampler_options is None:\n",
        "            sampler_options = [0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
        "        self.options = sampler_options\n",
        "        self.trials = trials\n",
        "\n",
        "    def forward(\n",
        "        self, image: Tensor, target: Optional[Dict[str, Tensor]] = None\n",
        "    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:\n",
        "        if target is None:\n",
        "            raise ValueError(\"The targets can't be None for this transform.\")\n",
        "\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            if image.ndimension() not in {2, 3}:\n",
        "                raise ValueError(f\"image should be 2/3 dimensional. Got {image.ndimension()} dimensions.\")\n",
        "            elif image.ndimension() == 2:\n",
        "                image = image.unsqueeze(0)\n",
        "\n",
        "        _, orig_h, orig_w = F.get_dimensions(image)\n",
        "\n",
        "        while True:\n",
        "            # sample an option\n",
        "            idx = int(torch.randint(low=0, high=len(self.options), size=(1,)))\n",
        "            min_jaccard_overlap = self.options[idx]\n",
        "            if min_jaccard_overlap >= 1.0:  # a value larger than 1 encodes the leave as-is option\n",
        "                return image, target\n",
        "\n",
        "            for _ in range(self.trials):\n",
        "                # check the aspect ratio limitations\n",
        "                r = self.min_scale + (self.max_scale - self.min_scale) * torch.rand(2)\n",
        "                new_w = int(orig_w * r[0])\n",
        "                new_h = int(orig_h * r[1])\n",
        "                aspect_ratio = new_w / new_h\n",
        "                if not (self.min_aspect_ratio <= aspect_ratio <= self.max_aspect_ratio):\n",
        "                    continue\n",
        "\n",
        "                # check for 0 area crops\n",
        "                r = torch.rand(2)\n",
        "                left = int((orig_w - new_w) * r[0])\n",
        "                top = int((orig_h - new_h) * r[1])\n",
        "                right = left + new_w\n",
        "                bottom = top + new_h\n",
        "                if left == right or top == bottom:\n",
        "                    continue\n",
        "\n",
        "                # check for any valid boxes with centers within the crop area\n",
        "                cx = 0.5 * (target[\"boxes\"][:, 0] + target[\"boxes\"][:, 2])\n",
        "                cy = 0.5 * (target[\"boxes\"][:, 1] + target[\"boxes\"][:, 3])\n",
        "                is_within_crop_area = (left < cx) & (cx < right) & (top < cy) & (cy < bottom)\n",
        "                if not is_within_crop_area.any():\n",
        "                    continue\n",
        "\n",
        "                # check at least 1 box with jaccard limitations\n",
        "                boxes = target[\"boxes\"][is_within_crop_area]\n",
        "                ious = torchvision.ops.boxes.box_iou(\n",
        "                    boxes, torch.tensor([[left, top, right, bottom]], dtype=boxes.dtype, device=boxes.device)\n",
        "                )\n",
        "                if ious.max() < min_jaccard_overlap:\n",
        "                    continue\n",
        "\n",
        "                # keep only valid boxes and perform cropping\n",
        "                target[\"boxes\"] = boxes\n",
        "                target[\"labels\"] = target[\"labels\"][is_within_crop_area]\n",
        "                target[\"boxes\"][:, 0::2] -= left\n",
        "                target[\"boxes\"][:, 1::2] -= top\n",
        "                target[\"boxes\"][:, 0::2].clamp_(min=0, max=new_w)\n",
        "                target[\"boxes\"][:, 1::2].clamp_(min=0, max=new_h)\n",
        "                image = F.crop(image, top, left, new_h, new_w)\n",
        "\n",
        "                return image, target\n",
        "\n",
        "\n",
        "class RandomZoomOut(nn.Module):\n",
        "    def __init__(\n",
        "        self, fill: Optional[List[float]] = None, side_range: Tuple[float, float] = (1.0, 4.0), p: float = 0.5\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if fill is None:\n",
        "            fill = [0.0, 0.0, 0.0]\n",
        "        self.fill = fill\n",
        "        self.side_range = side_range\n",
        "        if side_range[0] < 1.0 or side_range[0] > side_range[1]:\n",
        "            raise ValueError(f\"Invalid canvas side range provided {side_range}.\")\n",
        "        self.p = p\n",
        "\n",
        "    @torch.jit.unused\n",
        "    def _get_fill_value(self, is_pil):\n",
        "        # type: (bool) -> int\n",
        "        # We fake the type to make it work on JIT\n",
        "        return tuple(int(x) for x in self.fill) if is_pil else 0\n",
        "\n",
        "    def forward(\n",
        "        self, image: Tensor, target: Optional[Dict[str, Tensor]] = None\n",
        "    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            if image.ndimension() not in {2, 3}:\n",
        "                raise ValueError(f\"image should be 2/3 dimensional. Got {image.ndimension()} dimensions.\")\n",
        "            elif image.ndimension() == 2:\n",
        "                image = image.unsqueeze(0)\n",
        "\n",
        "        if torch.rand(1) >= self.p:\n",
        "            return image, target\n",
        "\n",
        "        _, orig_h, orig_w = F.get_dimensions(image)\n",
        "\n",
        "        r = self.side_range[0] + torch.rand(1) * (self.side_range[1] - self.side_range[0])\n",
        "        canvas_width = int(orig_w * r)\n",
        "        canvas_height = int(orig_h * r)\n",
        "\n",
        "        r = torch.rand(2)\n",
        "        left = int((canvas_width - orig_w) * r[0])\n",
        "        top = int((canvas_height - orig_h) * r[1])\n",
        "        right = canvas_width - (left + orig_w)\n",
        "        bottom = canvas_height - (top + orig_h)\n",
        "\n",
        "        if torch.jit.is_scripting():\n",
        "            fill = 0\n",
        "        else:\n",
        "            fill = self._get_fill_value(F._is_pil_image(image))\n",
        "\n",
        "        image = F.pad(image, [left, top, right, bottom], fill=fill)\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            # PyTorch's pad supports only integers on fill. So we need to overwrite the colour\n",
        "            v = torch.tensor(self.fill, device=image.device, dtype=image.dtype).view(-1, 1, 1)\n",
        "            image[..., :top, :] = image[..., :, :left] = image[..., (top + orig_h) :, :] = image[\n",
        "                ..., :, (left + orig_w) :\n",
        "            ] = v\n",
        "\n",
        "        if target is not None:\n",
        "            target[\"boxes\"][:, 0::2] += left\n",
        "            target[\"boxes\"][:, 1::2] += top\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class RandomPhotometricDistort(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        contrast: Tuple[float, float] = (0.5, 1.5),\n",
        "        saturation: Tuple[float, float] = (0.5, 1.5),\n",
        "        hue: Tuple[float, float] = (-0.05, 0.05),\n",
        "        brightness: Tuple[float, float] = (0.875, 1.125),\n",
        "        p: float = 0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self._brightness = T.ColorJitter(brightness=brightness)\n",
        "        self._contrast = T.ColorJitter(contrast=contrast)\n",
        "        self._hue = T.ColorJitter(hue=hue)\n",
        "        self._saturation = T.ColorJitter(saturation=saturation)\n",
        "        self.p = p\n",
        "\n",
        "    def forward(\n",
        "        self, image: Tensor, target: Optional[Dict[str, Tensor]] = None\n",
        "    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            if image.ndimension() not in {2, 3}:\n",
        "                raise ValueError(f\"image should be 2/3 dimensional. Got {image.ndimension()} dimensions.\")\n",
        "            elif image.ndimension() == 2:\n",
        "                image = image.unsqueeze(0)\n",
        "\n",
        "        r = torch.rand(7)\n",
        "\n",
        "        if r[0] < self.p:\n",
        "            image = self._brightness(image)\n",
        "\n",
        "        contrast_before = r[1] < 0.5\n",
        "        if contrast_before:\n",
        "            if r[2] < self.p:\n",
        "                image = self._contrast(image)\n",
        "\n",
        "        if r[3] < self.p:\n",
        "            image = self._saturation(image)\n",
        "\n",
        "        if r[4] < self.p:\n",
        "            image = self._hue(image)\n",
        "\n",
        "        if not contrast_before:\n",
        "            if r[5] < self.p:\n",
        "                image = self._contrast(image)\n",
        "\n",
        "        if r[6] < self.p:\n",
        "            channels, _, _ = F.get_dimensions(image)\n",
        "            permutation = torch.randperm(channels)\n",
        "\n",
        "            is_pil = F._is_pil_image(image)\n",
        "            if is_pil:\n",
        "                image = F.pil_to_tensor(image)\n",
        "                image = F.convert_image_dtype(image)\n",
        "            image = image[..., permutation, :, :]\n",
        "            if is_pil:\n",
        "                image = F.to_pil_image(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class ScaleJitter(nn.Module):\n",
        "    \"\"\"Randomly resizes the image and its bounding boxes  within the specified scale range.\n",
        "    The class implements the Scale Jitter augmentation as described in the paper\n",
        "    `\"Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation\" <https://arxiv.org/abs/2012.07177>`_.\n",
        "\n",
        "    Args:\n",
        "        target_size (tuple of ints): The target size for the transform provided in (height, weight) format.\n",
        "        scale_range (tuple of ints): scaling factor interval, e.g (a, b), then scale is randomly sampled from the\n",
        "            range a <= scale <= b.\n",
        "        interpolation (InterpolationMode): Desired interpolation enum defined by\n",
        "            :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.BILINEAR``.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        target_size: Tuple[int, int],\n",
        "        scale_range: Tuple[float, float] = (0.1, 2.0),\n",
        "        interpolation: InterpolationMode = InterpolationMode.BILINEAR,\n",
        "        antialias=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.target_size = target_size\n",
        "        self.scale_range = scale_range\n",
        "        self.interpolation = interpolation\n",
        "        self.antialias = antialias\n",
        "\n",
        "    def forward(\n",
        "        self, image: Tensor, target: Optional[Dict[str, Tensor]] = None\n",
        "    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            if image.ndimension() not in {2, 3}:\n",
        "                raise ValueError(f\"image should be 2/3 dimensional. Got {image.ndimension()} dimensions.\")\n",
        "            elif image.ndimension() == 2:\n",
        "                image = image.unsqueeze(0)\n",
        "\n",
        "        _, orig_height, orig_width = F.get_dimensions(image)\n",
        "\n",
        "        scale = self.scale_range[0] + torch.rand(1) * (self.scale_range[1] - self.scale_range[0])\n",
        "        r = min(self.target_size[1] / orig_height, self.target_size[0] / orig_width) * scale\n",
        "        new_width = int(orig_width * r)\n",
        "        new_height = int(orig_height * r)\n",
        "\n",
        "        image = F.resize(image, [new_height, new_width], interpolation=self.interpolation, antialias=self.antialias)\n",
        "\n",
        "        if target is not None:\n",
        "            target[\"boxes\"][:, 0::2] *= new_width / orig_width\n",
        "            target[\"boxes\"][:, 1::2] *= new_height / orig_height\n",
        "            if \"masks\" in target:\n",
        "                target[\"masks\"] = F.resize(\n",
        "                    target[\"masks\"],\n",
        "                    [new_height, new_width],\n",
        "                    interpolation=InterpolationMode.NEAREST,\n",
        "                    antialias=self.antialias,\n",
        "                )\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "class FixedSizeCrop(nn.Module):\n",
        "    def __init__(self, size, fill=0, padding_mode=\"constant\"):\n",
        "        super().__init__()\n",
        "        size = tuple(T._setup_size(size, error_msg=\"Please provide only two dimensions (h, w) for size.\"))\n",
        "        self.crop_height = size[0]\n",
        "        self.crop_width = size[1]\n",
        "        self.fill = fill  # TODO: Fill is currently respected only on PIL. Apply tensor patch.\n",
        "        self.padding_mode = padding_mode\n",
        "\n",
        "    def _pad(self, img, target, padding):\n",
        "        # Taken from the functional_tensor.py pad\n",
        "        if isinstance(padding, int):\n",
        "            pad_left = pad_right = pad_top = pad_bottom = padding\n",
        "        elif len(padding) == 1:\n",
        "            pad_left = pad_right = pad_top = pad_bottom = padding[0]\n",
        "        elif len(padding) == 2:\n",
        "            pad_left = pad_right = padding[0]\n",
        "            pad_top = pad_bottom = padding[1]\n",
        "        else:\n",
        "            pad_left = padding[0]\n",
        "            pad_top = padding[1]\n",
        "            pad_right = padding[2]\n",
        "            pad_bottom = padding[3]\n",
        "\n",
        "        padding = [pad_left, pad_top, pad_right, pad_bottom]\n",
        "        img = F.pad(img, padding, self.fill, self.padding_mode)\n",
        "        if target is not None:\n",
        "            target[\"boxes\"][:, 0::2] += pad_left\n",
        "            target[\"boxes\"][:, 1::2] += pad_top\n",
        "            if \"masks\" in target:\n",
        "                target[\"masks\"] = F.pad(target[\"masks\"], padding, 0, \"constant\")\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def _crop(self, img, target, top, left, height, width):\n",
        "        img = F.crop(img, top, left, height, width)\n",
        "        if target is not None:\n",
        "            boxes = target[\"boxes\"]\n",
        "            boxes[:, 0::2] -= left\n",
        "            boxes[:, 1::2] -= top\n",
        "            boxes[:, 0::2].clamp_(min=0, max=width)\n",
        "            boxes[:, 1::2].clamp_(min=0, max=height)\n",
        "\n",
        "            is_valid = (boxes[:, 0] < boxes[:, 2]) & (boxes[:, 1] < boxes[:, 3])\n",
        "\n",
        "            target[\"boxes\"] = boxes[is_valid]\n",
        "            target[\"labels\"] = target[\"labels\"][is_valid]\n",
        "            if \"masks\" in target:\n",
        "                target[\"masks\"] = F.crop(target[\"masks\"][is_valid], top, left, height, width)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def forward(self, img, target=None):\n",
        "        _, height, width = F.get_dimensions(img)\n",
        "        new_height = min(height, self.crop_height)\n",
        "        new_width = min(width, self.crop_width)\n",
        "\n",
        "        if new_height != height or new_width != width:\n",
        "            offset_height = max(height - self.crop_height, 0)\n",
        "            offset_width = max(width - self.crop_width, 0)\n",
        "\n",
        "            r = torch.rand(1)\n",
        "            top = int(offset_height * r)\n",
        "            left = int(offset_width * r)\n",
        "\n",
        "            img, target = self._crop(img, target, top, left, new_height, new_width)\n",
        "\n",
        "        pad_bottom = max(self.crop_height - new_height, 0)\n",
        "        pad_right = max(self.crop_width - new_width, 0)\n",
        "        if pad_bottom != 0 or pad_right != 0:\n",
        "            img, target = self._pad(img, target, [0, 0, pad_right, pad_bottom])\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n",
        "class RandomShortestSize(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        min_size: Union[List[int], Tuple[int], int],\n",
        "        max_size: int,\n",
        "        interpolation: InterpolationMode = InterpolationMode.BILINEAR,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.min_size = [min_size] if isinstance(min_size, int) else list(min_size)\n",
        "        self.max_size = max_size\n",
        "        self.interpolation = interpolation\n",
        "\n",
        "    def forward(\n",
        "        self, image: Tensor, target: Optional[Dict[str, Tensor]] = None\n",
        "    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:\n",
        "        _, orig_height, orig_width = F.get_dimensions(image)\n",
        "\n",
        "        min_size = self.min_size[torch.randint(len(self.min_size), (1,)).item()]\n",
        "        r = min(min_size / min(orig_height, orig_width), self.max_size / max(orig_height, orig_width))\n",
        "\n",
        "        new_width = int(orig_width * r)\n",
        "        new_height = int(orig_height * r)\n",
        "\n",
        "        image = F.resize(image, [new_height, new_width], interpolation=self.interpolation)\n",
        "\n",
        "        if target is not None:\n",
        "            target[\"boxes\"][:, 0::2] *= new_width / orig_width\n",
        "            target[\"boxes\"][:, 1::2] *= new_height / orig_height\n",
        "            if \"masks\" in target:\n",
        "                target[\"masks\"] = F.resize(\n",
        "                    target[\"masks\"], [new_height, new_width], interpolation=InterpolationMode.NEAREST\n",
        "                )\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "def _copy_paste(\n",
        "    image: torch.Tensor,\n",
        "    target: Dict[str, Tensor],\n",
        "    paste_image: torch.Tensor,\n",
        "    paste_target: Dict[str, Tensor],\n",
        "    blending: bool = True,\n",
        "    resize_interpolation: F.InterpolationMode = F.InterpolationMode.BILINEAR,\n",
        ") -> Tuple[torch.Tensor, Dict[str, Tensor]]:\n",
        "\n",
        "    # Random paste targets selection:\n",
        "    num_masks = len(paste_target[\"masks\"])\n",
        "\n",
        "    if num_masks < 1:\n",
        "        # Such degerante case with num_masks=0 can happen with LSJ\n",
        "        # Let's just return (image, target)\n",
        "        return image, target\n",
        "\n",
        "    # We have to please torch script by explicitly specifying dtype as torch.long\n",
        "    random_selection = torch.randint(0, num_masks, (num_masks,), device=paste_image.device)\n",
        "    random_selection = torch.unique(random_selection).to(torch.long)\n",
        "\n",
        "    paste_masks = paste_target[\"masks\"][random_selection]\n",
        "    paste_boxes = paste_target[\"boxes\"][random_selection]\n",
        "    paste_labels = paste_target[\"labels\"][random_selection]\n",
        "\n",
        "    masks = target[\"masks\"]\n",
        "\n",
        "    # We resize source and paste data if they have different sizes\n",
        "    # This is something we introduced here as originally the algorithm works\n",
        "    # on equal-sized data (for example, coming from LSJ data augmentations)\n",
        "    size1 = image.shape[-2:]\n",
        "    size2 = paste_image.shape[-2:]\n",
        "    if size1 != size2:\n",
        "        paste_image = F.resize(paste_image, size1, interpolation=resize_interpolation)\n",
        "        paste_masks = F.resize(paste_masks, size1, interpolation=F.InterpolationMode.NEAREST)\n",
        "        # resize bboxes:\n",
        "        ratios = torch.tensor((size1[1] / size2[1], size1[0] / size2[0]), device=paste_boxes.device)\n",
        "        paste_boxes = paste_boxes.view(-1, 2, 2).mul(ratios).view(paste_boxes.shape)\n",
        "\n",
        "    paste_alpha_mask = paste_masks.sum(dim=0) > 0\n",
        "\n",
        "    if blending:\n",
        "        paste_alpha_mask = F.gaussian_blur(\n",
        "            paste_alpha_mask.unsqueeze(0),\n",
        "            kernel_size=(5, 5),\n",
        "            sigma=[\n",
        "                2.0,\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    # Copy-paste images:\n",
        "    image = (image * (~paste_alpha_mask)) + (paste_image * paste_alpha_mask)\n",
        "\n",
        "    # Copy-paste masks:\n",
        "    masks = masks * (~paste_alpha_mask)\n",
        "    non_all_zero_masks = masks.sum((-1, -2)) > 0\n",
        "    masks = masks[non_all_zero_masks]\n",
        "\n",
        "    # Do a shallow copy of the target dict\n",
        "    out_target = {k: v for k, v in target.items()}\n",
        "\n",
        "    out_target[\"masks\"] = torch.cat([masks, paste_masks])\n",
        "\n",
        "    # Copy-paste boxes and labels\n",
        "    boxes = ops.masks_to_boxes(masks)\n",
        "    out_target[\"boxes\"] = torch.cat([boxes, paste_boxes])\n",
        "\n",
        "    labels = target[\"labels\"][non_all_zero_masks]\n",
        "    out_target[\"labels\"] = torch.cat([labels, paste_labels])\n",
        "\n",
        "    # Update additional optional keys: area and iscrowd if exist\n",
        "    if \"area\" in target:\n",
        "        out_target[\"area\"] = out_target[\"masks\"].sum((-1, -2)).to(torch.float32)\n",
        "\n",
        "    if \"iscrowd\" in target and \"iscrowd\" in paste_target:\n",
        "        # target['iscrowd'] size can be differ from mask size (non_all_zero_masks)\n",
        "        # For example, if previous transforms geometrically modifies masks/boxes/labels but\n",
        "        # does not update \"iscrowd\"\n",
        "        if len(target[\"iscrowd\"]) == len(non_all_zero_masks):\n",
        "            iscrowd = target[\"iscrowd\"][non_all_zero_masks]\n",
        "            paste_iscrowd = paste_target[\"iscrowd\"][random_selection]\n",
        "            out_target[\"iscrowd\"] = torch.cat([iscrowd, paste_iscrowd])\n",
        "\n",
        "    # Check for degenerated boxes and remove them\n",
        "    boxes = out_target[\"boxes\"]\n",
        "    degenerate_boxes = boxes[:, 2:] <= boxes[:, :2]\n",
        "    if degenerate_boxes.any():\n",
        "        valid_targets = ~degenerate_boxes.any(dim=1)\n",
        "\n",
        "        out_target[\"boxes\"] = boxes[valid_targets]\n",
        "        out_target[\"masks\"] = out_target[\"masks\"][valid_targets]\n",
        "        out_target[\"labels\"] = out_target[\"labels\"][valid_targets]\n",
        "\n",
        "        if \"area\" in out_target:\n",
        "            out_target[\"area\"] = out_target[\"area\"][valid_targets]\n",
        "        if \"iscrowd\" in out_target and len(out_target[\"iscrowd\"]) == len(valid_targets):\n",
        "            out_target[\"iscrowd\"] = out_target[\"iscrowd\"][valid_targets]\n",
        "\n",
        "    return image, out_target\n",
        "\n",
        "\n",
        "class SimpleCopyPaste(torch.nn.Module):\n",
        "    def __init__(self, blending=True, resize_interpolation=F.InterpolationMode.BILINEAR):\n",
        "        super().__init__()\n",
        "        self.resize_interpolation = resize_interpolation\n",
        "        self.blending = blending\n",
        "\n",
        "    def forward(\n",
        "        self, images: List[torch.Tensor], targets: List[Dict[str, Tensor]]\n",
        "    ) -> Tuple[List[torch.Tensor], List[Dict[str, Tensor]]]:\n",
        "        torch._assert(\n",
        "            isinstance(images, (list, tuple)) and all([isinstance(v, torch.Tensor) for v in images]),\n",
        "            \"images should be a list of tensors\",\n",
        "        )\n",
        "        torch._assert(\n",
        "            isinstance(targets, (list, tuple)) and len(images) == len(targets),\n",
        "            \"targets should be a list of the same size as images\",\n",
        "        )\n",
        "        for target in targets:\n",
        "            # Can not check for instance type dict with inside torch.jit.script\n",
        "            # torch._assert(isinstance(target, dict), \"targets item should be a dict\")\n",
        "            for k in [\"masks\", \"boxes\", \"labels\"]:\n",
        "                torch._assert(k in target, f\"Key {k} should be present in targets\")\n",
        "                torch._assert(isinstance(target[k], torch.Tensor), f\"Value for the key {k} should be a tensor\")\n",
        "\n",
        "        # images = [t1, t2, ..., tN]\n",
        "        # Let's define paste_images as shifted list of input images\n",
        "        # paste_images = [t2, t3, ..., tN, t1]\n",
        "        # FYI: in TF they mix data on the dataset level\n",
        "        images_rolled = images[-1:] + images[:-1]\n",
        "        targets_rolled = targets[-1:] + targets[:-1]\n",
        "\n",
        "        output_images: List[torch.Tensor] = []\n",
        "        output_targets: List[Dict[str, Tensor]] = []\n",
        "\n",
        "        for image, target, paste_image, paste_target in zip(images, targets, images_rolled, targets_rolled):\n",
        "            output_image, output_data = _copy_paste(\n",
        "                image,\n",
        "                target,\n",
        "                paste_image,\n",
        "                paste_target,\n",
        "                blending=self.blending,\n",
        "                resize_interpolation=self.resize_interpolation,\n",
        "            )\n",
        "            output_images.append(output_image)\n",
        "            output_targets.append(output_data)\n",
        "\n",
        "        return output_images, output_targets\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        s = f\"{self.__class__.__name__}(blending={self.blending}, resize_interpolation={self.resize_interpolation})\"\n",
        "        return s\n",
        "\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "def convert_coco_poly_to_mask(segmentations, height, width):\n",
        "    masks = []\n",
        "    for polygons in segmentations:\n",
        "        rles = coco_mask.frPyObjects(polygons, height, width)\n",
        "        mask = coco_mask.decode(rles)\n",
        "        if len(mask.shape) < 3:\n",
        "            mask = mask[..., None]\n",
        "        mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
        "        mask = mask.any(dim=2)\n",
        "        masks.append(mask)\n",
        "    if masks:\n",
        "        masks = torch.stack(masks, dim=0)\n",
        "    else:\n",
        "        masks = torch.zeros((0, height, width), dtype=torch.uint8)\n",
        "    return masks\n",
        "\n",
        "\n",
        "class ConvertCocoPolysToMask:\n",
        "    def __call__(self, image, target):\n",
        "        w, h = image.size\n",
        "\n",
        "        image_id = target[\"image_id\"]\n",
        "\n",
        "        anno = target[\"annotations\"]\n",
        "\n",
        "        anno = [obj for obj in anno if obj[\"iscrowd\"] == 0]\n",
        "\n",
        "        boxes = [obj[\"bbox\"] for obj in anno]\n",
        "        # guard against no boxes via resizing\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)\n",
        "        boxes[:, 2:] += boxes[:, :2]\n",
        "        boxes[:, 0::2].clamp_(min=0, max=w)\n",
        "        boxes[:, 1::2].clamp_(min=0, max=h)\n",
        "\n",
        "        classes = [obj[\"category_id\"] for obj in anno]\n",
        "        classes = torch.tensor(classes, dtype=torch.int64)\n",
        "\n",
        "        segmentations = [obj[\"segmentation\"] for obj in anno]\n",
        "        masks = convert_coco_poly_to_mask(segmentations, h, w)\n",
        "\n",
        "        keypoints = None\n",
        "        if anno and \"keypoints\" in anno[0]:\n",
        "            keypoints = [obj[\"keypoints\"] for obj in anno]\n",
        "            keypoints = torch.as_tensor(keypoints, dtype=torch.float32)\n",
        "            num_keypoints = keypoints.shape[0]\n",
        "            if num_keypoints:\n",
        "                keypoints = keypoints.view(num_keypoints, -1, 3)\n",
        "\n",
        "        keep = (boxes[:, 3] > boxes[:, 1]) & (boxes[:, 2] > boxes[:, 0])\n",
        "        boxes = boxes[keep]\n",
        "        classes = classes[keep]\n",
        "        masks = masks[keep]\n",
        "        if keypoints is not None:\n",
        "            keypoints = keypoints[keep]\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = classes\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "        if keypoints is not None:\n",
        "            target[\"keypoints\"] = keypoints\n",
        "\n",
        "        # for conversion to coco api\n",
        "        area = torch.tensor([obj[\"area\"] for obj in anno])\n",
        "        iscrowd = torch.tensor([obj[\"iscrowd\"] for obj in anno])\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "def _coco_remove_images_without_annotations(dataset, cat_list=None):\n",
        "    def _has_only_empty_bbox(anno):\n",
        "        return all(any(o <= 1 for o in obj[\"bbox\"][2:]) for obj in anno)\n",
        "\n",
        "    def _count_visible_keypoints(anno):\n",
        "        return sum(sum(1 for v in ann[\"keypoints\"][2::3] if v > 0) for ann in anno)\n",
        "\n",
        "    min_keypoints_per_image = 10\n",
        "\n",
        "    def _has_valid_annotation(anno):\n",
        "        # if it's empty, there is no annotation\n",
        "        if len(anno) == 0:\n",
        "            return False\n",
        "        # if all boxes have close to zero area, there is no annotation\n",
        "        if _has_only_empty_bbox(anno):\n",
        "            return False\n",
        "        # keypoints task have a slight different criteria for considering\n",
        "        # if an annotation is valid\n",
        "        if \"keypoints\" not in anno[0]:\n",
        "            return True\n",
        "        # for keypoint detection tasks, only consider valid images those\n",
        "        # containing at least min_keypoints_per_image\n",
        "        if _count_visible_keypoints(anno) >= min_keypoints_per_image:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    ids = []\n",
        "    for ds_idx, img_id in enumerate(dataset.ids):\n",
        "        ann_ids = dataset.coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
        "        anno = dataset.coco.loadAnns(ann_ids)\n",
        "        if cat_list:\n",
        "            anno = [obj for obj in anno if obj[\"category_id\"] in cat_list]\n",
        "        if _has_valid_annotation(anno):\n",
        "            ids.append(ds_idx)\n",
        "\n",
        "    dataset = torch.utils.data.Subset(dataset, ids)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def convert_to_coco_api(ds):\n",
        "    coco_ds = COCO()\n",
        "    # annotation IDs need to start at 1, not 0, see torchvision issue #1530\n",
        "    ann_id = 1\n",
        "    dataset = {\"images\": [], \"categories\": [], \"annotations\": []}\n",
        "    categories = set()\n",
        "    for img_idx in range(len(ds)):\n",
        "        # find better way to get target\n",
        "        # targets = ds.get_annotations(img_idx)\n",
        "        img, targets = ds[img_idx]\n",
        "        image_id = targets[\"image_id\"]\n",
        "        img_dict = {}\n",
        "        img_dict[\"id\"] = image_id\n",
        "        img_dict[\"height\"] = img.shape[-2]\n",
        "        img_dict[\"width\"] = img.shape[-1]\n",
        "        dataset[\"images\"].append(img_dict)\n",
        "        bboxes = targets[\"boxes\"].clone()\n",
        "        bboxes[:, 2:] -= bboxes[:, :2]\n",
        "        bboxes = bboxes.tolist()\n",
        "        labels = targets[\"labels\"].tolist()\n",
        "        areas = targets[\"area\"].tolist()\n",
        "        iscrowd = targets[\"iscrowd\"].tolist()\n",
        "        if \"masks\" in targets:\n",
        "            masks = targets[\"masks\"]\n",
        "            # make masks Fortran contiguous for coco_mask\n",
        "            masks = masks.permute(0, 2, 1).contiguous().permute(0, 2, 1)\n",
        "        if \"keypoints\" in targets:\n",
        "            keypoints = targets[\"keypoints\"]\n",
        "            keypoints = keypoints.reshape(keypoints.shape[0], -1).tolist()\n",
        "        num_objs = len(bboxes)\n",
        "        for i in range(num_objs):\n",
        "            ann = {}\n",
        "            ann[\"image_id\"] = image_id\n",
        "            ann[\"bbox\"] = bboxes[i]\n",
        "            ann[\"category_id\"] = labels[i]\n",
        "            categories.add(labels[i])\n",
        "            ann[\"area\"] = areas[i]\n",
        "            ann[\"iscrowd\"] = iscrowd[i]\n",
        "            ann[\"id\"] = ann_id\n",
        "            if \"masks\" in targets:\n",
        "                ann[\"segmentation\"] = coco_mask.encode(masks[i].numpy())\n",
        "            if \"keypoints\" in targets:\n",
        "                ann[\"keypoints\"] = keypoints[i]\n",
        "                ann[\"num_keypoints\"] = sum(k != 0 for k in keypoints[i][2::3])\n",
        "            dataset[\"annotations\"].append(ann)\n",
        "            ann_id += 1\n",
        "    dataset[\"categories\"] = [{\"id\": i} for i in sorted(categories)]\n",
        "    coco_ds.dataset = dataset\n",
        "    coco_ds.createIndex()\n",
        "    return coco_ds\n",
        "\n",
        "\n",
        "def get_coco_api_from_dataset(dataset):\n",
        "    # FIXME: This is... awful?\n",
        "    for _ in range(10):\n",
        "        if isinstance(dataset, torchvision.datasets.CocoDetection):\n",
        "            break\n",
        "        if isinstance(dataset, torch.utils.data.Subset):\n",
        "            dataset = dataset.dataset\n",
        "    if isinstance(dataset, torchvision.datasets.CocoDetection):\n",
        "        return dataset.coco\n",
        "    return convert_to_coco_api(dataset)\n",
        "\n",
        "\n",
        "class CocoDetection(torchvision.datasets.CocoDetection):\n",
        "    def __init__(self, img_folder, ann_file, transforms):\n",
        "        super().__init__(img_folder, ann_file)\n",
        "        self._transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super().__getitem__(idx)\n",
        "        image_id = self.ids[idx]\n",
        "        target = dict(image_id=image_id, annotations=target)\n",
        "        if self._transforms is not None:\n",
        "            img, target = self._transforms(img, target)\n",
        "        return img, target\n",
        "\n",
        "\n",
        "def get_coco(root, image_set, transforms, mode=\"instances\", use_v2=False, with_masks=False):\n",
        "    anno_file_template = \"{}_{}2017.json\"\n",
        "    PATHS = {\n",
        "        \"train\": (\"train2017\", os.path.join(\"annotations\", anno_file_template.format(mode, \"train\"))),\n",
        "        \"val\": (\"val2017\", os.path.join(\"annotations\", anno_file_template.format(mode, \"val\"))),\n",
        "        # \"train\": (\"val2017\", os.path.join(\"annotations\", anno_file_template.format(mode, \"val\")))\n",
        "    }\n",
        "\n",
        "    img_folder, ann_file = PATHS[image_set]\n",
        "    img_folder = os.path.join(root, img_folder)\n",
        "    ann_file = os.path.join(root, ann_file)\n",
        "\n",
        "    if use_v2:\n",
        "        from torchvision.datasets import wrap_dataset_for_transforms_v2\n",
        "\n",
        "        dataset = torchvision.datasets.CocoDetection(img_folder, ann_file, transforms=transforms)\n",
        "        target_keys = [\"boxes\", \"labels\", \"image_id\"]\n",
        "        if with_masks:\n",
        "            target_keys += [\"masks\"]\n",
        "        dataset = wrap_dataset_for_transforms_v2(dataset, target_keys=target_keys)\n",
        "    else:\n",
        "        # TODO: handle with_masks for V1?\n",
        "        t = [ConvertCocoPolysToMask()]\n",
        "        if transforms is not None:\n",
        "            t.append(transforms)\n",
        "        transforms = T.Compose(t)\n",
        "\n",
        "        dataset = CocoDetection(img_folder, ann_file, transforms=transforms)\n",
        "\n",
        "    if image_set == \"train\":\n",
        "        dataset = _coco_remove_images_without_annotations(dataset)\n",
        "\n",
        "    # dataset = torch.utils.data.Subset(dataset, [i for i in range(500)])\n",
        "\n",
        "    return dataset\n",
        "\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "class SmoothedValue:\n",
        "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
        "    window or the global series average.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size=20, fmt=None):\n",
        "        if fmt is None:\n",
        "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
        "        self.deque = deque(maxlen=window_size)\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.deque.append(value)\n",
        "        self.count += n\n",
        "        self.total += value * n\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        \"\"\"\n",
        "        Warning: does not synchronize the deque!\n",
        "        \"\"\"\n",
        "        if not is_dist_avail_and_initialized():\n",
        "            return\n",
        "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device=\"cuda\")\n",
        "        dist.barrier()\n",
        "        dist.all_reduce(t)\n",
        "        t = t.tolist()\n",
        "        self.count = int(t[0])\n",
        "        self.total = t[1]\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        d = torch.tensor(list(self.deque))\n",
        "        return d.median().item()\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
        "        return d.mean().item()\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return max(self.deque)\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.deque[-1]\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fmt.format(\n",
        "            median=self.median, avg=self.avg, global_avg=self.global_avg, max=self.max, value=self.value\n",
        "        )\n",
        "\n",
        "\n",
        "def all_gather(data):\n",
        "    \"\"\"\n",
        "    Run all_gather on arbitrary picklable data (not necessarily tensors)\n",
        "    Args:\n",
        "        data: any picklable object\n",
        "    Returns:\n",
        "        list[data]: list of data gathered from each rank\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size == 1:\n",
        "        return [data]\n",
        "    data_list = [None] * world_size\n",
        "    dist.all_gather_object(data_list, data)\n",
        "    return data_list\n",
        "\n",
        "\n",
        "def reduce_dict(input_dict, average=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_dict (dict): all the values will be reduced\n",
        "        average (bool): whether to do average or sum\n",
        "    Reduce the values in the dictionary from all processes so that all processes\n",
        "    have the averaged results. Returns a dict with the same fields as\n",
        "    input_dict, after reduction.\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size < 2:\n",
        "        return input_dict\n",
        "    with torch.inference_mode():\n",
        "        names = []\n",
        "        values = []\n",
        "        # sort the keys so that they are consistent across processes\n",
        "        for k in sorted(input_dict.keys()):\n",
        "            names.append(k)\n",
        "            values.append(input_dict[k])\n",
        "        values = torch.stack(values, dim=0)\n",
        "        dist.all_reduce(values)\n",
        "        if average:\n",
        "            values /= world_size\n",
        "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
        "    return reduced_dict\n",
        "\n",
        "\n",
        "class MetricLogger:\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = defaultdict(SmoothedValue)\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                v = v.item()\n",
        "            assert isinstance(v, (float, int))\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(f\"{name}: {str(meter)}\")\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for meter in self.meters.values():\n",
        "            meter.synchronize_between_processes()\n",
        "\n",
        "    def add_meter(self, name, meter):\n",
        "        self.meters[name] = meter\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if not header:\n",
        "            header = \"\"\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        data_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        space_fmt = \":\" + str(len(str(len(iterable)))) + \"d\"\n",
        "        if torch.cuda.is_available():\n",
        "            log_msg = self.delimiter.join(\n",
        "                [\n",
        "                    header,\n",
        "                    \"[{0\" + space_fmt + \"}/{1}]\",\n",
        "                    \"eta: {eta}\",\n",
        "                    \"{meters}\",\n",
        "                    \"time: {time}\",\n",
        "                    \"data: {data}\",\n",
        "                    \"max mem: {memory:.0f}\",\n",
        "                ]\n",
        "            )\n",
        "        else:\n",
        "            log_msg = self.delimiter.join(\n",
        "                [header, \"[{0\" + space_fmt + \"}/{1}]\", \"eta: {eta}\", \"{meters}\", \"time: {time}\", \"data: {data}\"]\n",
        "            )\n",
        "        MB = 1024.0 * 1024.0\n",
        "        for obj in iterable:\n",
        "            data_time.update(time.time() - end)\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                if torch.cuda.is_available():\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i,\n",
        "                            len(iterable),\n",
        "                            eta=eta_string,\n",
        "                            meters=str(self),\n",
        "                            time=str(iter_time),\n",
        "                            data=str(data_time),\n",
        "                            memory=torch.cuda.max_memory_allocated() / MB,\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i, len(iterable), eta=eta_string, meters=str(self), time=str(iter_time), data=str(data_time)\n",
        "                        )\n",
        "                    )\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print(f\"{header} Total time: {total_time_str} ({total_time / len(iterable):.4f} s / it)\")\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError as e:\n",
        "        if e.errno != errno.EEXIST:\n",
        "            raise\n",
        "\n",
        "\n",
        "def setup_for_distributed(is_master):\n",
        "    \"\"\"\n",
        "    This function disables printing when not in master process\n",
        "    \"\"\"\n",
        "    import builtins as __builtin__\n",
        "\n",
        "    builtin_print = __builtin__.print\n",
        "\n",
        "    def print(*args, **kwargs):\n",
        "        force = kwargs.pop(\"force\", False)\n",
        "        if is_master or force:\n",
        "            builtin_print(*args, **kwargs)\n",
        "\n",
        "    __builtin__.print = print\n",
        "\n",
        "\n",
        "def is_dist_avail_and_initialized():\n",
        "    if not dist.is_available():\n",
        "        return False\n",
        "    if not dist.is_initialized():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def get_world_size():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 1\n",
        "    return dist.get_world_size()\n",
        "\n",
        "\n",
        "def get_rank():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 0\n",
        "    return dist.get_rank()\n",
        "\n",
        "\n",
        "def is_main_process():\n",
        "    return get_rank() == 0\n",
        "\n",
        "\n",
        "def save_on_master(*args, **kwargs):\n",
        "    if is_main_process():\n",
        "        torch.save(*args, **kwargs)\n",
        "\n",
        "\n",
        "def init_distributed_mode(args):\n",
        "    if \"RANK\" in os.environ and \"WORLD_SIZE\" in os.environ:\n",
        "        args.rank = int(os.environ[\"RANK\"])\n",
        "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "        args.gpu = int(os.environ[\"LOCAL_RANK\"])\n",
        "    elif \"SLURM_PROCID\" in os.environ:\n",
        "        args.rank = int(os.environ[\"SLURM_PROCID\"])\n",
        "        args.gpu = args.rank % torch.cuda.device_count()\n",
        "    else:\n",
        "        print(\"Not using distributed mode\")\n",
        "        args.distributed = False\n",
        "        return\n",
        "\n",
        "    args.distributed = True\n",
        "\n",
        "    torch.cuda.set_device(args.gpu)\n",
        "    args.dist_backend = \"nccl\"\n",
        "    print(f\"| distributed init (rank {args.rank}): {args.dist_url}\", flush=True)\n",
        "    torch.distributed.init_process_group(\n",
        "        backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank\n",
        "    )\n",
        "    torch.distributed.barrier()\n",
        "    setup_for_distributed(args.rank == 0)\n",
        "\n",
        "###\n",
        "###\n",
        "\n",
        "class CocoEvaluator:\n",
        "    def __init__(self, coco_gt, iou_types):\n",
        "        if not isinstance(iou_types, (list, tuple)):\n",
        "            raise TypeError(f\"This constructor expects iou_types of type list or tuple, instead  got {type(iou_types)}\")\n",
        "        coco_gt = copy.deepcopy(coco_gt)\n",
        "        self.coco_gt = coco_gt\n",
        "\n",
        "        self.iou_types = iou_types\n",
        "        self.coco_eval = {}\n",
        "        for iou_type in iou_types:\n",
        "            self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)\n",
        "            coco_eval = COCOeval(coco_gt, iouType=iou_type)\n",
        "            coco_eval.params.kpt_oks_sigmas = np.array([.5, .5, .5, .5, .5]) / 10.0\n",
        "            self.coco_eval[iou_type] = coco_eval\n",
        "\n",
        "        self.img_ids = []\n",
        "        self.eval_imgs = {k: [] for k in iou_types}\n",
        "\n",
        "    def update(self, predictions):\n",
        "        img_ids = list(np.unique(list(predictions.keys())))\n",
        "        self.img_ids.extend(img_ids)\n",
        "\n",
        "        for iou_type in self.iou_types:\n",
        "            results = self.prepare(predictions, iou_type)\n",
        "            with redirect_stdout(io.StringIO()):\n",
        "                coco_dt = COCO.loadRes(self.coco_gt, results) if results else COCO()\n",
        "            coco_eval = self.coco_eval[iou_type]\n",
        "\n",
        "            coco_eval.cocoDt = coco_dt\n",
        "            coco_eval.params.imgIds = list(img_ids)\n",
        "            img_ids, eval_imgs = evaluate_singlearg(coco_eval)\n",
        "\n",
        "            self.eval_imgs[iou_type].append(eval_imgs)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for iou_type in self.iou_types:\n",
        "            self.eval_imgs[iou_type] = np.concatenate(self.eval_imgs[iou_type], 2)\n",
        "            create_common_coco_eval(self.coco_eval[iou_type], self.img_ids, self.eval_imgs[iou_type])\n",
        "\n",
        "    def accumulate(self):\n",
        "        for coco_eval in self.coco_eval.values():\n",
        "            coco_eval.accumulate()\n",
        "\n",
        "    def summarize(self):\n",
        "        for iou_type, coco_eval in self.coco_eval.items():\n",
        "            print(f\"IoU metric: {iou_type}\")\n",
        "            coco_eval.summarize()\n",
        "\n",
        "    def prepare(self, predictions, iou_type):\n",
        "        if iou_type == \"bbox\":\n",
        "            return self.prepare_for_coco_detection(predictions)\n",
        "        if iou_type == \"segm\":\n",
        "            return self.prepare_for_coco_segmentation(predictions)\n",
        "        if iou_type == \"keypoints\":\n",
        "            return self.prepare_for_coco_keypoint(predictions)\n",
        "        raise ValueError(f\"Unknown iou type {iou_type}\")\n",
        "\n",
        "    def prepare_for_coco_detection(self, predictions):\n",
        "        coco_results = []\n",
        "        for original_id, prediction in predictions.items():\n",
        "            if len(prediction) == 0:\n",
        "                continue\n",
        "\n",
        "            boxes = prediction[\"boxes\"]\n",
        "            boxes = convert_to_xywh(boxes).tolist()\n",
        "            scores = prediction[\"scores\"].tolist()\n",
        "            labels = prediction[\"labels\"].tolist()\n",
        "\n",
        "            coco_results.extend(\n",
        "                [\n",
        "                    {\n",
        "                        \"image_id\": original_id,\n",
        "                        \"category_id\": labels[k],\n",
        "                        \"bbox\": box,\n",
        "                        \"score\": scores[k],\n",
        "                    }\n",
        "                    for k, box in enumerate(boxes)\n",
        "                ]\n",
        "            )\n",
        "        return coco_results\n",
        "\n",
        "    def prepare_for_coco_segmentation(self, predictions):\n",
        "        coco_results = []\n",
        "        for original_id, prediction in predictions.items():\n",
        "            if len(prediction) == 0:\n",
        "                continue\n",
        "\n",
        "            scores = prediction[\"scores\"]\n",
        "            labels = prediction[\"labels\"]\n",
        "            masks = prediction[\"masks\"]\n",
        "\n",
        "            masks = masks > 0.5\n",
        "\n",
        "            scores = prediction[\"scores\"].tolist()\n",
        "            labels = prediction[\"labels\"].tolist()\n",
        "\n",
        "            rles = [\n",
        "                mask_util.encode(np.array(mask[0, :, :, np.newaxis], dtype=np.uint8, order=\"F\"))[0] for mask in masks\n",
        "            ]\n",
        "            for rle in rles:\n",
        "                rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n",
        "\n",
        "            coco_results.extend(\n",
        "                [\n",
        "                    {\n",
        "                        \"image_id\": original_id,\n",
        "                        \"category_id\": labels[k],\n",
        "                        \"segmentation\": rle,\n",
        "                        \"score\": scores[k],\n",
        "                    }\n",
        "                    for k, rle in enumerate(rles)\n",
        "                ]\n",
        "            )\n",
        "        return coco_results\n",
        "\n",
        "    def prepare_for_coco_keypoint(self, predictions):\n",
        "        coco_results = []\n",
        "        for original_id, prediction in predictions.items():\n",
        "            if len(prediction) == 0:\n",
        "                continue\n",
        "\n",
        "            boxes = prediction[\"boxes\"]\n",
        "            boxes = convert_to_xywh(boxes).tolist()\n",
        "            scores = prediction[\"scores\"].tolist()\n",
        "            labels = prediction[\"labels\"].tolist()\n",
        "            keypoints = prediction[\"keypoints\"]\n",
        "            keypoints = keypoints.flatten(start_dim=1).tolist()\n",
        "\n",
        "            coco_results.extend(\n",
        "                [\n",
        "                    {\n",
        "                        \"image_id\": original_id,\n",
        "                        \"category_id\": labels[k],\n",
        "                        \"keypoints\": keypoint,\n",
        "                        \"score\": scores[k],\n",
        "                    }\n",
        "                    for k, keypoint in enumerate(keypoints)\n",
        "                ]\n",
        "            )\n",
        "        return coco_results\n",
        "\n",
        "\n",
        "def convert_to_xywh(boxes):\n",
        "    xmin, ymin, xmax, ymax = boxes.unbind(1)\n",
        "    return torch.stack((xmin, ymin, xmax - xmin, ymax - ymin), dim=1)\n",
        "\n",
        "\n",
        "def merge(img_ids, eval_imgs):\n",
        "    all_img_ids = utils.all_gather(img_ids)\n",
        "    all_eval_imgs = utils.all_gather(eval_imgs)\n",
        "\n",
        "    merged_img_ids = []\n",
        "    for p in all_img_ids:\n",
        "        merged_img_ids.extend(p)\n",
        "\n",
        "    merged_eval_imgs = []\n",
        "    for p in all_eval_imgs:\n",
        "        merged_eval_imgs.append(p)\n",
        "\n",
        "    merged_img_ids = np.array(merged_img_ids)\n",
        "    merged_eval_imgs = np.concatenate(merged_eval_imgs, 2)\n",
        "\n",
        "    # keep only unique (and in sorted order) images\n",
        "    merged_img_ids, idx = np.unique(merged_img_ids, return_index=True)\n",
        "    merged_eval_imgs = merged_eval_imgs[..., idx]\n",
        "\n",
        "    return merged_img_ids, merged_eval_imgs\n",
        "\n",
        "\n",
        "def create_common_coco_eval(coco_eval, img_ids, eval_imgs):\n",
        "    img_ids, eval_imgs = merge(img_ids, eval_imgs)\n",
        "    img_ids = list(img_ids)\n",
        "    eval_imgs = list(eval_imgs.flatten())\n",
        "\n",
        "    coco_eval.evalImgs = eval_imgs\n",
        "    coco_eval.params.imgIds = img_ids\n",
        "    coco_eval._paramsEval = copy.deepcopy(coco_eval.params)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###\n",
        "###\n",
        "###\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq, scaler=None):\n",
        "    model.train()\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter(\"lr\", utils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
        "    header = f\"Epoch: [{epoch}]\"\n",
        "\n",
        "    lr_scheduler = None\n",
        "    if epoch == 0:\n",
        "        warmup_factor = 1.0 / 1000\n",
        "        warmup_iters = min(1000, len(data_loader) - 1)\n",
        "\n",
        "        lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
        "        )\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in t.items()} for t in targets]\n",
        "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # reduce losses over all GPUs for logging purposes\n",
        "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
        "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "\n",
        "        loss_value = losses_reduced.item()\n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(f\"Loss is {loss_value}, stopping training\")\n",
        "            print(loss_dict_reduced)\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if scaler is not None:\n",
        "            scaler.scale(losses).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    return metric_logger\n",
        "\n",
        "\n",
        "def _get_iou_types(model):\n",
        "    model_without_ddp = model\n",
        "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
        "        model_without_ddp = model.module\n",
        "    iou_types = [\"bbox\"]\n",
        "    if isinstance(model_without_ddp, torchvision.models.detection.MaskRCNN):\n",
        "        iou_types.append(\"segm\")\n",
        "    if isinstance(model_without_ddp, torchvision.models.detection.KeypointRCNN):\n",
        "        iou_types.append(\"keypoints\")\n",
        "    return iou_types\n",
        "\n",
        "def evaluate_singlearg(imgs):\n",
        "    with redirect_stdout(io.StringIO()):\n",
        "        imgs.evaluate()\n",
        "    return imgs.params.imgIds, np.asarray(imgs.evalImgs).reshape(-1, len(imgs.params.areaRng), len(imgs.params.imgIds))\n",
        "\n",
        "#@torch.inference_mode()\n",
        "def evaluate(model, data_loader, device):\n",
        "    n_threads = torch.get_num_threads()\n",
        "    # FIXME remove this and make paste_masks_in_image run on the GPU\n",
        "    torch.set_num_threads(1)\n",
        "    cpu_device = torch.device(\"cpu\")\n",
        "    model.eval()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = \"Test:\"\n",
        "\n",
        "    coco = get_coco_api_from_dataset(data_loader.dataset)\n",
        "    iou_types = _get_iou_types(model)\n",
        "    coco_evaluator = CocoEvaluator(coco, iou_types)\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, 100, header):\n",
        "        images = list(img.to(device) for img in images)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        model_time = time.time()\n",
        "        outputs = model(images)\n",
        "\n",
        "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
        "        model_time = time.time() - model_time\n",
        "\n",
        "        res = {target[\"image_id\"]: output for target, output in zip(targets, outputs)}\n",
        "        evaluator_time = time.time()\n",
        "        coco_evaluator.update(res)\n",
        "        evaluator_time = time.time() - evaluator_time\n",
        "        metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n",
        "\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    coco_evaluator.synchronize_between_processes()\n",
        "\n",
        "    # accumulate predictions from all images\n",
        "    coco_evaluator.accumulate()\n",
        "    coco_evaluator.summarize()\n",
        "    torch.set_num_threads(n_threads)\n",
        "    return coco_evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdA_UCg94zg-"
      },
      "source": [
        "(Ignore -- automated!)\n",
        "Next, download coco_eval.py , coco_utils.py, engine.py, group_by_aspect_ratio.py, presets.py, train.py, transforms.py, utils.py files from this repository (https://github.com/pytorch/vision/tree/main/references/detection) and place them into the folder with your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DaNTw0f_564t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a20e7a2-671c-464c-872f-c64a720e23a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  8388  100  8388    0     0  18892      0 --:--:-- --:--:-- --:--:-- 18891\n"
          ]
        }
      ],
      "source": [
        "#!curl -o coco_eval.py https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\n",
        "#!curl -o coco_utils.py https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\n",
        "#!curl -o engine.py https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\n",
        "#!curl -o group_by_aspect_ratio.py https://raw.githubusercontent.com/pytorch/vision/main/references/detection/group_by_aspect_ratio.py\n",
        "#!curl -o presets.py https://raw.githubusercontent.com/pytorch/vision/main/references/detection/presets.py\n",
        "#!curl -o train.py https://raw.githubusercontent.com/pytorch/vision/main/references/detection/train.py\n",
        "#!curl -o transforms.py https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\n",
        "!curl -o utils.py https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iMVBf7V64qIX"
      },
      "outputs": [],
      "source": [
        "#import transforms, utils, engine, train\n",
        "import utils\n",
        "#from utils import collate_fn\n",
        "#from engine import train_one_epoch, evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0W_41qg_4IHc"
      },
      "outputs": [],
      "source": [
        "#self.coco_eval[iou_type] = COCOeval(coco_gt, iouType=iou_type)\n",
        "#coco_eval = COCOeval(coco_gt, iouType=iou_type)\n",
        "#coco_eval.params.kpt_oks_sigmas = np.array([.5, .5, .5, .5, .5]) / 10.0\n",
        "#self.coco_eval[iou_type] = coco_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LU7OZAz94nb7"
      },
      "outputs": [],
      "source": [
        "def train_transform():\n",
        "    return A.Compose([\n",
        "        A.Sequential([\n",
        "            A.RandomRotate90(p=1), # Random rotation of an image by 90 degrees zero or more times\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, brightness_by_max=True, always_apply=False, p=1), # Random change of brightness & contrast\n",
        "        ], p=1)\n",
        "    ],\n",
        "    keypoint_params=A.KeypointParams(format='xy'), # More about keypoint formats used in albumentations library read at https://albumentations.ai/docs/getting_started/keypoints_augmentation/\n",
        "    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['bboxes_labels']) # Bboxes should have labels, read more at https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sosCMU1RprtC"
      },
      "outputs": [],
      "source": [
        "class ClassDataset(Dataset):\n",
        "   def __init__(self, root, transform=None, demo=False):\n",
        "       self.root = root\n",
        "       #print(root)\n",
        "       self.transform = transform\n",
        "       self.demo = demo # Use demo=True if you need transformed and original images (for example, for visualization purposes)\n",
        "       self.imgs_files = sorted(os.listdir(os.path.join(root, \"images\")))\n",
        "       #print(len(self.imgs_files))\n",
        "       self.annotations_files = sorted(os.listdir(os.path.join(root, \"annotations\")))\n",
        "\n",
        "\n",
        "   def __getitem__(self, idx):\n",
        "       img_path = os.path.join(self.root, \"images\", self.imgs_files[idx])\n",
        "       annotations_path = os.path.join(self.root, \"annotations\", self.annotations_files[idx])\n",
        "\n",
        "\n",
        "       img_original = cv2.imread(img_path)\n",
        "       img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "       with open(annotations_path) as f:\n",
        "           data = json.load(f)\n",
        "           bboxes_original = data['bboxes'][0]\n",
        "           x0, y0 = int(bboxes_original['bbox_x']), int(bboxes_original['bbox_y'])\n",
        "           x1, y1 = x0 + int(bboxes_original['bbox_width']), y0 + int(bboxes_original['bbox_height'])\n",
        "           bboxes_original = [[x0, y0, x1, y1]]\n",
        "\n",
        "           #List will be in order of Center, Top, Bottom, Left, Right\n",
        "           keypoints_list_of_lists=[\n",
        "               [0, 0, 1], #Center\n",
        "               [0, 0, 1], #Top\n",
        "               [0, 0, 1], #Bottom\n",
        "               [0, 0, 1], #Left\n",
        "               [0, 0, 1]  #Right\n",
        "           ]\n",
        "\n",
        "           keypoints_original = data['keypoints']\n",
        "           for keypoint in keypoints_original:\n",
        "             #print(keypoint[\"label_name\"])\n",
        "             keypoint_name=keypoint[\"label_name\"]\n",
        "             x, y = int(keypoint[\"x\"]), int(keypoint[\"y\"])\n",
        "             if keypoint_name=='Center':\n",
        "               keypoints_list_of_lists[0] = [x, y, 1]\n",
        "             elif keypoint_name == 'Top':\n",
        "               keypoints_list_of_lists[1] = [x, y, 1]\n",
        "             elif keypoint_name == 'Bottom':\n",
        "               keypoints_list_of_lists[2] = [x, y, 1]\n",
        "             elif keypoint_name == 'Left':\n",
        "               keypoints_list_of_lists[3] = [x, y, 1]\n",
        "             elif keypoint_name == 'Right':\n",
        "               keypoints_list_of_lists[4] = [x, y, 1]\n",
        "           #print(keypoints_list_of_lists)\n",
        "           keypoints_original=[keypoints_list_of_lists]\n",
        "\n",
        "           # All objects are glue tubes\n",
        "           bboxes_labels_original = ['Glue tube' for _ in bboxes_original]\n",
        "\n",
        "\n",
        "       if self.transform:\n",
        "           # Converting keypoints from [x,y,visibility]-format to [x, y]-format + Flattening nested list of keypoints\n",
        "           # For example, if we have the following list of keypoints for three objects (each object has two keypoints):\n",
        "           # [[obj1_kp1, obj1_kp2], [obj2_kp1, obj2_kp2], [obj3_kp1, obj3_kp2]], where each keypoint is in [x, y]-format\n",
        "           # Then we need to convert it to the following list:\n",
        "           # [obj1_kp1, obj1_kp2, obj2_kp1, obj2_kp2, obj3_kp1, obj3_kp2]\n",
        "           keypoints_original_flattened = [el[0:2] for kp in keypoints_original for el in kp]\n",
        "\n",
        "\n",
        "           # Apply augmentations\n",
        "           transformed = self.transform(image=img_original, bboxes=bboxes_original, bboxes_labels=bboxes_labels_original, keypoints=keypoints_original_flattened)\n",
        "           img = transformed['image']\n",
        "           bboxes = transformed['bboxes']\n",
        "\n",
        "\n",
        "           # Unflattening list transformed['keypoints']\n",
        "           # For example, if we have the following list of keypoints for three objects (each object has two keypoints):\n",
        "           # [obj1_kp1, obj1_kp2, obj2_kp1, obj2_kp2, obj3_kp1, obj3_kp2], where each keypoint is in [x, y]-format\n",
        "           # Then we need to convert it to the following list:\n",
        "           # [[obj1_kp1, obj1_kp2], [obj2_kp1, obj2_kp2], [obj3_kp1, obj3_kp2]]\n",
        "           keypoints_transformed_unflattened = np.reshape(np.array(transformed['keypoints']), (-1,5,2)).tolist()\n",
        "\n",
        "\n",
        "           # Converting transformed keypoints from [x, y]-format to [x,y,visibility]-format by appending original visibilities to transformed coordinates of keypoints\n",
        "           keypoints = []\n",
        "           for o_idx, obj in enumerate(keypoints_transformed_unflattened): # Iterating over objects\n",
        "               obj_keypoints = []\n",
        "               for k_idx, kp in enumerate(obj): # Iterating over keypoints in each object\n",
        "                   # kp - coordinates of keypoint\n",
        "                   # keypoints_original[o_idx][k_idx][2] - original visibility of keypoint\n",
        "                   obj_keypoints.append(kp + [keypoints_original[o_idx][k_idx][2]])\n",
        "               keypoints.append(obj_keypoints)\n",
        "\n",
        "\n",
        "       else:\n",
        "           img, bboxes, keypoints = img_original, bboxes_original, keypoints_original\n",
        "\n",
        "\n",
        "       # Convert everything into a torch tensor\n",
        "       bboxes = torch.as_tensor(bboxes, dtype=torch.float32)\n",
        "       target = {}\n",
        "       target[\"boxes\"] = bboxes\n",
        "       target[\"labels\"] = torch.as_tensor([1 for _ in bboxes], dtype=torch.int64) # all objects are glue tubes\n",
        "       target[\"image_id\"] = idx # torch.tensor([idx])\n",
        "       target[\"area\"] = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
        "       target[\"iscrowd\"] = torch.zeros(len(bboxes), dtype=torch.int64)\n",
        "       target[\"keypoints\"] = torch.as_tensor(keypoints, dtype=torch.float32)\n",
        "       img = F.to_tensor(img)\n",
        "\n",
        "\n",
        "       bboxes_original = torch.as_tensor(bboxes_original, dtype=torch.float32)\n",
        "       target_original = {}\n",
        "       target_original[\"boxes\"] = bboxes_original\n",
        "       target_original[\"labels\"] = torch.as_tensor([1 for _ in bboxes_original], dtype=torch.int64) # all objects are glue tubes\n",
        "       target_original[\"image_id\"] = idx #torch.tensor([idx])\n",
        "       target_original[\"area\"] = (bboxes_original[:, 3] - bboxes_original[:, 1]) * (bboxes_original[:, 2] - bboxes_original[:, 0])\n",
        "       target_original[\"iscrowd\"] = torch.zeros(len(bboxes_original), dtype=torch.int64)\n",
        "       target_original[\"keypoints\"] = torch.as_tensor(keypoints_original, dtype=torch.float32)\n",
        "       img_original = F.to_tensor(img_original)\n",
        "\n",
        "\n",
        "       if self.demo:\n",
        "           return img, target, img_original, target_original\n",
        "       else:\n",
        "           return img, target\n",
        "\n",
        "\n",
        "   def __len__(self):\n",
        "       return len(self.imgs_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zbsmuOuSpys1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "KEYPOINTS_FOLDER_TRAIN = '/content/drive/MyDrive/TennisMLProject'\n",
        "dataset = ClassDataset(KEYPOINTS_FOLDER_TRAIN, transform=train_transform(), demo=False)\n",
        "\n",
        "# Define the sizes of your train, validation, and test sets\n",
        "train_size = int(0.7 * len(dataset))  # 70% of data for training\n",
        "val_size = int(0.15 * len(dataset))   # 15% of data for validation\n",
        "test_size = len(dataset) - train_size - val_size  # Remaining data for testing\n",
        "\n",
        "# Use random_split to split the dataset\n",
        "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Optionally, you can create DataLoader for each set\n",
        "train_loader = DataLoader(train_data, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_data, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "#data_loader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "#iterator = iter(train_loader)\n",
        "#batch = next(iterator)\n",
        "\n",
        "#print(\"Original targets:\\n\", batch[3], \"\\n\\n\")\n",
        "#print(\"Transformed targets:\\n\", batch[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qaKOGL15p6Dj"
      },
      "outputs": [],
      "source": [
        "#keypoints_classes_ids2names = {0: 'Center', 1: 'Top' , 2: 'Bottom' , 3: 'Left' , 4: 'Right'}\n",
        "\n",
        "#def visualize(image, bboxes, keypoints, image_original=None, bboxes_original=None, keypoints_original=None):\n",
        "    #fontsize = 18\n",
        "\n",
        "   #for bbox in bboxes:\n",
        "        #start_point = (bbox[0], bbox[1])\n",
        "        #end_point = (bbox[2], bbox[3])\n",
        "        #image = cv2.rectangle(image.copy(), start_point, end_point, (0,255,0), 2)\n",
        "\n",
        "   # for kps in keypoints:\n",
        "        #for idx, kp in enumerate(kps):\n",
        "           # image = cv2.circle(image.copy(), tuple(kp), 5, (255,0,0), 10)\n",
        "            #image = cv2.putText(image.copy(), \" \" + keypoints_classes_ids2names[idx], tuple(kp), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,0,0), 3, cv2.LINE_AA)\n",
        "\n",
        "    #if image_original is None and keypoints_original is None:\n",
        "        #plt.figure(figsize=(40,40))\n",
        "        #plt.imshow(image)\n",
        "\n",
        "    #else:\n",
        "        #for bbox in bboxes_original:\n",
        "            #start_point = (bbox[0], bbox[1])\n",
        "            #end_point = (bbox[2], bbox[3])\n",
        "            #image_original = cv2.rectangle(image_original.copy(), start_point, end_point, (0,255,0), 2)\n",
        "\n",
        "        #for kps in keypoints_original:\n",
        "            #for idx, kp in enumerate(kps):\n",
        "               #image_original = cv2.circle(image_original, tuple(kp), 5, (255,0,0), 10)\n",
        "                #image_original = cv2.putText(image_original, \" \" + keypoints_classes_ids2names[idx], tuple(kp), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,0,0), 3, cv2.LINE_AA)\n",
        "\n",
        "        #f, ax = plt.subplots(1, 2, figsize=(40, 20))\n",
        "\n",
        "        #ax[0].imshow(image_original)\n",
        "        #ax[0].set_title('Original image', fontsize=fontsize)\n",
        "\n",
        "        #ax[1].imshow(image)\n",
        "        #ax[1].set_title('Transformed image', fontsize=fontsize)\n",
        "\n",
        "#image = (batch[0][0].permute(1,2,0).numpy() * 255).astype(np.uint8)\n",
        "#bboxes = batch[1][0]['boxes'].detach().cpu().numpy().astype(np.int32).tolist()\n",
        "\n",
        "#keypoints = []\n",
        "#for kps in batch[1][0]['keypoints'].detach().cpu().numpy().astype(np.int32).tolist():\n",
        "    #keypoints.append([kp[:2] for kp in kps])\n",
        "\n",
        "#image_original = (batch[2][0].permute(1,2,0).numpy() * 255).astype(np.uint8)\n",
        "#bboxes_original = batch[3][0]['boxes'].detach().cpu().numpy().astype(np.int32).tolist()\n",
        "\n",
        "#keypoints_original = []\n",
        "#for kps in batch[3][0]['keypoints'].detach().cpu().numpy().astype(np.int32).tolist():\n",
        "    #keypoints_original.append([kp[:2] for kp in kps])\n",
        "\n",
        "#visualize(image, bboxes, keypoints, image_original, bboxes_original, keypoints_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "60QNKlUXTrns"
      },
      "outputs": [],
      "source": [
        "def get_model(num_keypoints, weights_path=None):\n",
        "\n",
        "    anchor_generator = AnchorGenerator(sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.25, 0.5, 0.75, 1.0, 2.0, 3.0, 4.0))\n",
        "    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=False,\n",
        "                                                                   pretrained_backbone=True,\n",
        "                                                                   num_keypoints=num_keypoints,\n",
        "                                                                   num_classes = 2, # Background is the first class, object is the second class\n",
        "                                                                   rpn_anchor_generator=anchor_generator)\n",
        "\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjNCrw-6T3oA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69be75c1-84c2-4d5c-8b7d-5bbc31e4e394"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights_backbone=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 51.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [  0/280]  eta: 0:29:56  lr: 0.000005  loss: 9.4556 (9.4556)  loss_classifier: 0.7152 (0.7152)  loss_box_reg: 0.0140 (0.0140)  loss_keypoint: 8.0345 (8.0345)  loss_objectness: 0.6892 (0.6892)  loss_rpn_box_reg: 0.0027 (0.0027)  time: 6.4176  data: 3.4585  max mem: 1124\n",
            "Epoch: [0]  [279/280]  eta: 0:00:01  lr: 0.001000  loss: 6.1314 (6.7500)  loss_classifier: 0.0778 (0.1241)  loss_box_reg: 0.1012 (0.0713)  loss_keypoint: 5.9334 (6.3242)  loss_objectness: 0.0360 (0.2218)  loss_rpn_box_reg: 0.0048 (0.0086)  time: 1.4214  data: 1.1218  max mem: 1690\n",
            "Epoch: [0] Total time: 0:06:56 (1.4889 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:01:05  model_time: 0.2765 (0.2765)  evaluator_time: 0.0030 (0.0030)  time: 1.0851  data: 0.7748  max mem: 1690\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1431 (0.1432)  evaluator_time: 0.0039 (0.0037)  time: 0.8951  data: 0.7195  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9084 s / it)\n",
            "Averaged stats: model_time: 0.1431 (0.1432)  evaluator_time: 0.0039 (0.0037)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.014\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.003\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.038\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.017\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.038\n",
            "Validation Loss: 0.003353398491238952\n",
            "Epoch: [1]  [  0/280]  eta: 0:04:57  lr: 0.001000  loss: 6.3478 (6.3478)  loss_classifier: 0.0427 (0.0427)  loss_box_reg: 0.0714 (0.0714)  loss_keypoint: 6.1821 (6.1821)  loss_objectness: 0.0427 (0.0427)  loss_rpn_box_reg: 0.0089 (0.0089)  time: 1.0613  data: 0.7198  max mem: 2296\n",
            "Epoch: [1]  [279/280]  eta: 0:00:00  lr: 0.001000  loss: 4.8179 (5.1288)  loss_classifier: 0.0569 (0.0521)  loss_box_reg: 0.1235 (0.0903)  loss_keypoint: 4.5946 (4.9541)  loss_objectness: 0.0295 (0.0248)  loss_rpn_box_reg: 0.0043 (0.0076)  time: 0.7483  data: 0.4522  max mem: 2296\n",
            "Epoch: [1] Total time: 0:03:31 (0.7546 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:01:01  model_time: 0.1874 (0.1874)  evaluator_time: 0.0037 (0.0037)  time: 1.0333  data: 0.8100  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1413 (0.1425)  evaluator_time: 0.0037 (0.0038)  time: 0.8876  data: 0.7121  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9016 s / it)\n",
            "Averaged stats: model_time: 0.1413 (0.1425)  evaluator_time: 0.0037 (0.0038)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.149\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.005\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.033\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.058\n",
            "Validation Loss: 0.004702984979069397\n",
            "Epoch: [2]  [  0/280]  eta: 0:04:40  lr: 0.001000  loss: 4.9665 (4.9665)  loss_classifier: 0.0587 (0.0587)  loss_box_reg: 0.1479 (0.1479)  loss_keypoint: 4.7207 (4.7207)  loss_objectness: 0.0270 (0.0270)  loss_rpn_box_reg: 0.0122 (0.0122)  time: 1.0006  data: 0.6711  max mem: 2296\n",
            "Epoch: [2]  [279/280]  eta: 0:00:00  lr: 0.001000  loss: 3.8087 (4.3383)  loss_classifier: 0.0385 (0.0441)  loss_box_reg: 0.0759 (0.0817)  loss_keypoint: 3.6675 (4.1902)  loss_objectness: 0.0128 (0.0155)  loss_rpn_box_reg: 0.0051 (0.0068)  time: 0.7783  data: 0.4710  max mem: 2296\n",
            "Epoch: [2] Total time: 0:03:35 (0.7706 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:01:01  model_time: 0.1839 (0.1839)  evaluator_time: 0.0026 (0.0026)  time: 1.0232  data: 0.8055  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1304 (0.1355)  evaluator_time: 0.0033 (0.0034)  time: 0.8884  data: 0.7212  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9115 s / it)\n",
            "Averaged stats: model_time: 0.1304 (0.1355)  evaluator_time: 0.0033 (0.0034)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.018\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.090\n",
            "Validation Loss: 0.01751732944349226\n",
            "Epoch: [3]  [  0/280]  eta: 0:04:06  lr: 0.001000  loss: 3.7931 (3.7931)  loss_classifier: 0.0333 (0.0333)  loss_box_reg: 0.0484 (0.0484)  loss_keypoint: 3.6883 (3.6883)  loss_objectness: 0.0152 (0.0152)  loss_rpn_box_reg: 0.0079 (0.0079)  time: 0.8818  data: 0.6244  max mem: 2296\n",
            "Epoch: [3]  [279/280]  eta: 0:00:00  lr: 0.001000  loss: 3.6443 (3.9624)  loss_classifier: 0.0288 (0.0362)  loss_box_reg: 0.0709 (0.0697)  loss_keypoint: 3.5765 (3.8391)  loss_objectness: 0.0087 (0.0110)  loss_rpn_box_reg: 0.0036 (0.0064)  time: 0.7934  data: 0.4762  max mem: 2296\n",
            "Epoch: [3] Total time: 0:03:34 (0.7665 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:58  model_time: 0.1609 (0.1609)  evaluator_time: 0.0022 (0.0022)  time: 0.9732  data: 0.7786  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1207 (0.1241)  evaluator_time: 0.0023 (0.0024)  time: 0.9089  data: 0.7541  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9151 s / it)\n",
            "Averaged stats: model_time: 0.1207 (0.1241)  evaluator_time: 0.0023 (0.0024)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.028\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.078\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.028\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.108\n",
            "Validation Loss: 0.027675581528123022\n",
            "Epoch: [4]  [  0/280]  eta: 0:04:45  lr: 0.001000  loss: 3.9321 (3.9321)  loss_classifier: 0.0225 (0.0225)  loss_box_reg: 0.0567 (0.0567)  loss_keypoint: 3.8418 (3.8418)  loss_objectness: 0.0089 (0.0089)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 1.0208  data: 0.6730  max mem: 2296\n",
            "Epoch: [4]  [279/280]  eta: 0:00:00  lr: 0.001000  loss: 3.6195 (3.6704)  loss_classifier: 0.0286 (0.0328)  loss_box_reg: 0.0701 (0.0657)  loss_keypoint: 3.4880 (3.5572)  loss_objectness: 0.0098 (0.0089)  loss_rpn_box_reg: 0.0047 (0.0058)  time: 0.7788  data: 0.4735  max mem: 2296\n",
            "Epoch: [4] Total time: 0:03:35 (0.7696 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:59  model_time: 0.1769 (0.1769)  evaluator_time: 0.0022 (0.0022)  time: 0.9837  data: 0.7724  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1250 (0.1286)  evaluator_time: 0.0026 (0.0026)  time: 0.8771  data: 0.7168  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9005 s / it)\n",
            "Averaged stats: model_time: 0.1250 (0.1286)  evaluator_time: 0.0026 (0.0026)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.078\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.180\n",
            "Validation Loss: 0.07805254882393907\n",
            "Epoch: [5]  [  0/280]  eta: 0:04:39  lr: 0.000300  loss: 2.6504 (2.6504)  loss_classifier: 0.0259 (0.0259)  loss_box_reg: 0.0706 (0.0706)  loss_keypoint: 2.5385 (2.5385)  loss_objectness: 0.0074 (0.0074)  loss_rpn_box_reg: 0.0079 (0.0079)  time: 0.9983  data: 0.6520  max mem: 2296\n",
            "Epoch: [5]  [279/280]  eta: 0:00:00  lr: 0.000300  loss: 2.8018 (2.9865)  loss_classifier: 0.0234 (0.0288)  loss_box_reg: 0.0416 (0.0552)  loss_keypoint: 2.7157 (2.8885)  loss_objectness: 0.0027 (0.0082)  loss_rpn_box_reg: 0.0030 (0.0058)  time: 0.7831  data: 0.4653  max mem: 2296\n",
            "Epoch: [5] Total time: 0:03:36 (0.7717 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:58  model_time: 0.1675 (0.1675)  evaluator_time: 0.0023 (0.0023)  time: 0.9678  data: 0.7668  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1215 (0.1248)  evaluator_time: 0.0024 (0.0024)  time: 0.9020  data: 0.7455  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8973 s / it)\n",
            "Averaged stats: model_time: 0.1215 (0.1248)  evaluator_time: 0.0024 (0.0024)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.134\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.297\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.063\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.150\n",
            "Validation Loss: 0.06253564138928368\n",
            "Epoch: [6]  [  0/280]  eta: 0:04:27  lr: 0.000300  loss: 3.5765 (3.5765)  loss_classifier: 0.0187 (0.0187)  loss_box_reg: 0.0516 (0.0516)  loss_keypoint: 3.4797 (3.4797)  loss_objectness: 0.0213 (0.0213)  loss_rpn_box_reg: 0.0051 (0.0051)  time: 0.9571  data: 0.6660  max mem: 2296\n",
            "Epoch: [6]  [279/280]  eta: 0:00:00  lr: 0.000300  loss: 2.4259 (2.8277)  loss_classifier: 0.0225 (0.0268)  loss_box_reg: 0.0456 (0.0513)  loss_keypoint: 2.3497 (2.7367)  loss_objectness: 0.0044 (0.0075)  loss_rpn_box_reg: 0.0034 (0.0054)  time: 0.7862  data: 0.4818  max mem: 2296\n",
            "Epoch: [6] Total time: 0:03:35 (0.7707 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:57  model_time: 0.1632 (0.1632)  evaluator_time: 0.0027 (0.0027)  time: 0.9645  data: 0.7674  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1211 (0.1248)  evaluator_time: 0.0024 (0.0024)  time: 0.9012  data: 0.7453  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8960 s / it)\n",
            "Averaged stats: model_time: 0.1211 (0.1248)  evaluator_time: 0.0024 (0.0024)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.078\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.120\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.120\n",
            "Validation Loss: 0.04393211192730636\n",
            "Epoch: [7]  [  0/280]  eta: 0:04:23  lr: 0.000300  loss: 2.6884 (2.6884)  loss_classifier: 0.0269 (0.0269)  loss_box_reg: 0.0332 (0.0332)  loss_keypoint: 2.6095 (2.6095)  loss_objectness: 0.0181 (0.0181)  loss_rpn_box_reg: 0.0006 (0.0006)  time: 0.9394  data: 0.6619  max mem: 2296\n",
            "Epoch: [7]  [279/280]  eta: 0:00:00  lr: 0.000300  loss: 2.5861 (2.7011)  loss_classifier: 0.0225 (0.0265)  loss_box_reg: 0.0426 (0.0499)  loss_keypoint: 2.5318 (2.6130)  loss_objectness: 0.0027 (0.0064)  loss_rpn_box_reg: 0.0034 (0.0052)  time: 0.7719  data: 0.4783  max mem: 2296\n",
            "Epoch: [7] Total time: 0:03:36 (0.7725 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:59  model_time: 0.1681 (0.1681)  evaluator_time: 0.0019 (0.0019)  time: 0.9906  data: 0.7889  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1206 (0.1231)  evaluator_time: 0.0023 (0.0023)  time: 0.8942  data: 0.7392  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8976 s / it)\n",
            "Averaged stats: model_time: 0.1206 (0.1231)  evaluator_time: 0.0023 (0.0023)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.150\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.198\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.198\n",
            "Validation Loss: 0.09534205272298711\n",
            "Epoch: [8]  [  0/280]  eta: 0:03:44  lr: 0.000300  loss: 2.3038 (2.3038)  loss_classifier: 0.0237 (0.0237)  loss_box_reg: 0.0525 (0.0525)  loss_keypoint: 2.2197 (2.2197)  loss_objectness: 0.0011 (0.0011)  loss_rpn_box_reg: 0.0068 (0.0068)  time: 0.8002  data: 0.5098  max mem: 2296\n",
            "Epoch: [8]  [279/280]  eta: 0:00:00  lr: 0.000300  loss: 2.7662 (2.6263)  loss_classifier: 0.0250 (0.0239)  loss_box_reg: 0.0447 (0.0472)  loss_keypoint: 2.6891 (2.5442)  loss_objectness: 0.0035 (0.0062)  loss_rpn_box_reg: 0.0045 (0.0048)  time: 0.7719  data: 0.4694  max mem: 2296\n",
            "Epoch: [8] Total time: 0:03:34 (0.7667 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:58  model_time: 0.1707 (0.1707)  evaluator_time: 0.0019 (0.0019)  time: 0.9768  data: 0.7728  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1199 (0.1227)  evaluator_time: 0.0023 (0.0022)  time: 0.8755  data: 0.7215  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8895 s / it)\n",
            "Averaged stats: model_time: 0.1199 (0.1227)  evaluator_time: 0.0023 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.253\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.052\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.112\n",
            "Validation Loss: 0.03590564030500961\n",
            "Epoch: [9]  [  0/280]  eta: 0:04:32  lr: 0.000300  loss: 2.0141 (2.0141)  loss_classifier: 0.0135 (0.0135)  loss_box_reg: 0.0348 (0.0348)  loss_keypoint: 1.9526 (1.9526)  loss_objectness: 0.0078 (0.0078)  loss_rpn_box_reg: 0.0053 (0.0053)  time: 0.9748  data: 0.6545  max mem: 2296\n",
            "Epoch: [9]  [279/280]  eta: 0:00:00  lr: 0.000300  loss: 2.3154 (2.6149)  loss_classifier: 0.0202 (0.0251)  loss_box_reg: 0.0412 (0.0469)  loss_keypoint: 2.2358 (2.5318)  loss_objectness: 0.0030 (0.0060)  loss_rpn_box_reg: 0.0026 (0.0050)  time: 0.7764  data: 0.4709  max mem: 2296\n",
            "Epoch: [9] Total time: 0:03:36 (0.7727 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:50  model_time: 0.1665 (0.1665)  evaluator_time: 0.0017 (0.0017)  time: 0.8432  data: 0.6436  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1202 (0.1221)  evaluator_time: 0.0022 (0.0023)  time: 0.8966  data: 0.7418  max mem: 2296\n",
            "Test: Total time: 0:00:52 (0.8818 s / it)\n",
            "Averaged stats: model_time: 0.1202 (0.1221)  evaluator_time: 0.0022 (0.0023)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.277\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.066\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.040\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.130\n",
            "Validation Loss: 0.039543352971422335\n",
            "Epoch: [10]  [  0/280]  eta: 0:04:10  lr: 0.000090  loss: 1.7420 (1.7420)  loss_classifier: 0.0183 (0.0183)  loss_box_reg: 0.0325 (0.0325)  loss_keypoint: 1.6765 (1.6765)  loss_objectness: 0.0096 (0.0096)  loss_rpn_box_reg: 0.0052 (0.0052)  time: 0.8952  data: 0.6081  max mem: 2296\n",
            "Epoch: [10]  [279/280]  eta: 0:00:00  lr: 0.000090  loss: 2.0860 (2.3623)  loss_classifier: 0.0214 (0.0231)  loss_box_reg: 0.0373 (0.0433)  loss_keypoint: 2.0257 (2.2840)  loss_objectness: 0.0072 (0.0068)  loss_rpn_box_reg: 0.0026 (0.0051)  time: 0.7517  data: 0.4454  max mem: 2296\n",
            "Epoch: [10] Total time: 0:03:36 (0.7717 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:58  model_time: 0.1677 (0.1677)  evaluator_time: 0.0019 (0.0019)  time: 0.9699  data: 0.7689  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1186 (0.1214)  evaluator_time: 0.0022 (0.0022)  time: 0.9056  data: 0.7527  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8951 s / it)\n",
            "Averaged stats: model_time: 0.1186 (0.1214)  evaluator_time: 0.0022 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.266\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.107\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.175\n",
            "Validation Loss: 0.06453314563106778\n",
            "Epoch: [11]  [  0/280]  eta: 0:03:55  lr: 0.000090  loss: 1.8404 (1.8404)  loss_classifier: 0.0120 (0.0120)  loss_box_reg: 0.0253 (0.0253)  loss_keypoint: 1.7943 (1.7943)  loss_objectness: 0.0045 (0.0045)  loss_rpn_box_reg: 0.0041 (0.0041)  time: 0.8415  data: 0.4932  max mem: 2296\n",
            "Epoch: [11]  [279/280]  eta: 0:00:00  lr: 0.000090  loss: 2.1119 (2.2788)  loss_classifier: 0.0174 (0.0236)  loss_box_reg: 0.0340 (0.0421)  loss_keypoint: 2.0602 (2.2026)  loss_objectness: 0.0016 (0.0056)  loss_rpn_box_reg: 0.0027 (0.0049)  time: 0.7645  data: 0.4636  max mem: 2296\n",
            "Epoch: [11] Total time: 0:03:39 (0.7846 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:50  model_time: 0.1663 (0.1663)  evaluator_time: 0.0018 (0.0018)  time: 0.8447  data: 0.6448  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1193 (0.1214)  evaluator_time: 0.0022 (0.0022)  time: 0.8949  data: 0.7413  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8923 s / it)\n",
            "Averaged stats: model_time: 0.1193 (0.1214)  evaluator_time: 0.0022 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.252\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.036\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.049\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.036\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.113\n",
            "Validation Loss: 0.035584793773494994\n",
            "Epoch: [12]  [  0/280]  eta: 0:04:31  lr: 0.000090  loss: 1.8487 (1.8487)  loss_classifier: 0.0151 (0.0151)  loss_box_reg: 0.0713 (0.0713)  loss_keypoint: 1.7411 (1.7411)  loss_objectness: 0.0165 (0.0165)  loss_rpn_box_reg: 0.0048 (0.0048)  time: 0.9693  data: 0.6668  max mem: 2296\n",
            "Epoch: [12]  [279/280]  eta: 0:00:00  lr: 0.000090  loss: 2.3507 (2.2556)  loss_classifier: 0.0279 (0.0237)  loss_box_reg: 0.0498 (0.0426)  loss_keypoint: 2.2289 (2.1791)  loss_objectness: 0.0027 (0.0054)  loss_rpn_box_reg: 0.0043 (0.0048)  time: 0.7503  data: 0.4420  max mem: 2296\n",
            "Epoch: [12] Total time: 0:03:36 (0.7727 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:50  model_time: 0.1549 (0.1549)  evaluator_time: 0.0017 (0.0017)  time: 0.8347  data: 0.6468  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1178 (0.1200)  evaluator_time: 0.0022 (0.0022)  time: 0.8697  data: 0.7173  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8867 s / it)\n",
            "Averaged stats: model_time: 0.1178 (0.1200)  evaluator_time: 0.0022 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.268\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.071\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.305\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.030\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.133\n",
            "Validation Loss: 0.030341034103410342\n",
            "Epoch: [13]  [  0/280]  eta: 0:04:04  lr: 0.000090  loss: 1.9893 (1.9893)  loss_classifier: 0.0272 (0.0272)  loss_box_reg: 0.0339 (0.0339)  loss_keypoint: 1.9260 (1.9260)  loss_objectness: 0.0006 (0.0006)  loss_rpn_box_reg: 0.0017 (0.0017)  time: 0.8719  data: 0.5817  max mem: 2296\n",
            "Epoch: [13]  [279/280]  eta: 0:00:00  lr: 0.000090  loss: 2.0319 (2.2133)  loss_classifier: 0.0209 (0.0223)  loss_box_reg: 0.0433 (0.0424)  loss_keypoint: 1.9166 (2.1382)  loss_objectness: 0.0013 (0.0056)  loss_rpn_box_reg: 0.0027 (0.0049)  time: 0.7707  data: 0.4624  max mem: 2296\n",
            "Epoch: [13] Total time: 0:03:34 (0.7673 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:50  model_time: 0.1626 (0.1626)  evaluator_time: 0.0020 (0.0020)  time: 0.8465  data: 0.6501  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1180 (0.1217)  evaluator_time: 0.0022 (0.0022)  time: 0.9222  data: 0.7693  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8990 s / it)\n",
            "Averaged stats: model_time: 0.1180 (0.1217)  evaluator_time: 0.0022 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.147\n",
            "Validation Loss: 0.051495337583782566\n",
            "Epoch: [14]  [  0/280]  eta: 0:04:07  lr: 0.000090  loss: 2.8276 (2.8276)  loss_classifier: 0.0144 (0.0144)  loss_box_reg: 0.0510 (0.0510)  loss_keypoint: 2.7572 (2.7572)  loss_objectness: 0.0022 (0.0022)  loss_rpn_box_reg: 0.0028 (0.0028)  time: 0.8845  data: 0.6018  max mem: 2296\n",
            "Epoch: [14]  [279/280]  eta: 0:00:00  lr: 0.000090  loss: 2.0376 (2.2315)  loss_classifier: 0.0207 (0.0235)  loss_box_reg: 0.0308 (0.0419)  loss_keypoint: 1.9841 (2.1559)  loss_objectness: 0.0018 (0.0056)  loss_rpn_box_reg: 0.0037 (0.0046)  time: 0.7794  data: 0.4678  max mem: 2296\n",
            "Epoch: [14] Total time: 0:03:38 (0.7810 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:58  model_time: 0.1555 (0.1555)  evaluator_time: 0.0020 (0.0020)  time: 0.9694  data: 0.7804  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1178 (0.1209)  evaluator_time: 0.0022 (0.0022)  time: 0.8927  data: 0.7400  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8955 s / it)\n",
            "Averaged stats: model_time: 0.1178 (0.1209)  evaluator_time: 0.0022 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.082\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.053\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.158\n",
            "Validation Loss: 0.053262465781461876\n",
            "Epoch: [15]  [  0/280]  eta: 0:04:34  lr: 0.000027  loss: 2.4969 (2.4969)  loss_classifier: 0.0455 (0.0455)  loss_box_reg: 0.0528 (0.0528)  loss_keypoint: 2.3968 (2.3968)  loss_objectness: 0.0006 (0.0006)  loss_rpn_box_reg: 0.0013 (0.0013)  time: 0.9812  data: 0.6763  max mem: 2296\n",
            "Epoch: [15]  [279/280]  eta: 0:00:00  lr: 0.000027  loss: 1.9846 (2.1286)  loss_classifier: 0.0265 (0.0222)  loss_box_reg: 0.0421 (0.0405)  loss_keypoint: 1.8490 (2.0561)  loss_objectness: 0.0023 (0.0051)  loss_rpn_box_reg: 0.0022 (0.0047)  time: 0.7390  data: 0.4353  max mem: 2296\n",
            "Epoch: [15] Total time: 0:03:37 (0.7775 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:59  model_time: 0.1673 (0.1673)  evaluator_time: 0.0019 (0.0019)  time: 0.9860  data: 0.7857  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1175 (0.1207)  evaluator_time: 0.0022 (0.0022)  time: 0.8862  data: 0.7339  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9014 s / it)\n",
            "Averaged stats: model_time: 0.1175 (0.1207)  evaluator_time: 0.0022 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.100\n",
            "Validation Loss: 0.02524358536649421\n",
            "Epoch: [16]  [  0/280]  eta: 0:04:27  lr: 0.000027  loss: 1.9213 (1.9213)  loss_classifier: 0.0174 (0.0174)  loss_box_reg: 0.0181 (0.0181)  loss_keypoint: 1.8669 (1.8669)  loss_objectness: 0.0172 (0.0172)  loss_rpn_box_reg: 0.0017 (0.0017)  time: 0.9571  data: 0.6565  max mem: 2296\n",
            "Epoch: [16]  [279/280]  eta: 0:00:00  lr: 0.000027  loss: 2.0632 (2.1066)  loss_classifier: 0.0216 (0.0226)  loss_box_reg: 0.0398 (0.0402)  loss_keypoint: 1.9213 (2.0342)  loss_objectness: 0.0017 (0.0049)  loss_rpn_box_reg: 0.0030 (0.0046)  time: 0.7777  data: 0.4675  max mem: 2296\n",
            "Epoch: [16] Total time: 0:03:35 (0.7696 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:58  model_time: 0.1672 (0.1672)  evaluator_time: 0.0019 (0.0019)  time: 0.9771  data: 0.7767  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1176 (0.1207)  evaluator_time: 0.0021 (0.0022)  time: 0.8779  data: 0.7259  max mem: 2296\n",
            "Test: Total time: 0:00:52 (0.8812 s / it)\n",
            "Averaged stats: model_time: 0.1176 (0.1207)  evaluator_time: 0.0021 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.034\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.122\n",
            "Validation Loss: 0.03379711281939005\n",
            "Epoch: [17]  [  0/280]  eta: 0:04:47  lr: 0.000027  loss: 1.7252 (1.7252)  loss_classifier: 0.0174 (0.0174)  loss_box_reg: 0.0294 (0.0294)  loss_keypoint: 1.6748 (1.6748)  loss_objectness: 0.0010 (0.0010)  loss_rpn_box_reg: 0.0026 (0.0026)  time: 1.0280  data: 0.6771  max mem: 2296\n",
            "Epoch: [17]  [279/280]  eta: 0:00:00  lr: 0.000027  loss: 1.9372 (2.0858)  loss_classifier: 0.0203 (0.0220)  loss_box_reg: 0.0344 (0.0389)  loss_keypoint: 1.8687 (2.0150)  loss_objectness: 0.0017 (0.0053)  loss_rpn_box_reg: 0.0031 (0.0046)  time: 0.7731  data: 0.4584  max mem: 2296\n",
            "Epoch: [17] Total time: 0:03:35 (0.7710 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:51  model_time: 0.1722 (0.1722)  evaluator_time: 0.0020 (0.0020)  time: 0.8553  data: 0.6496  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1183 (0.1198)  evaluator_time: 0.0022 (0.0021)  time: 0.8839  data: 0.7319  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8936 s / it)\n",
            "Averaged stats: model_time: 0.1183 (0.1198)  evaluator_time: 0.0022 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.226\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.035\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.112\n",
            "Validation Loss: 0.03507336887534907\n",
            "Epoch: [18]  [  0/280]  eta: 0:03:55  lr: 0.000027  loss: 2.9163 (2.9163)  loss_classifier: 0.0189 (0.0189)  loss_box_reg: 0.0508 (0.0508)  loss_keypoint: 2.8430 (2.8430)  loss_objectness: 0.0009 (0.0009)  loss_rpn_box_reg: 0.0026 (0.0026)  time: 0.8418  data: 0.5354  max mem: 2296\n",
            "Epoch: [18]  [279/280]  eta: 0:00:00  lr: 0.000027  loss: 1.9150 (2.0463)  loss_classifier: 0.0204 (0.0221)  loss_box_reg: 0.0330 (0.0402)  loss_keypoint: 1.8299 (1.9746)  loss_objectness: 0.0013 (0.0052)  loss_rpn_box_reg: 0.0028 (0.0044)  time: 0.7609  data: 0.4437  max mem: 2296\n",
            "Epoch: [18] Total time: 0:03:36 (0.7716 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:55  model_time: 0.1572 (0.1572)  evaluator_time: 0.0020 (0.0020)  time: 0.9183  data: 0.7276  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1187 (0.1206)  evaluator_time: 0.0021 (0.0021)  time: 0.8764  data: 0.7236  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8837 s / it)\n",
            "Averaged stats: model_time: 0.1187 (0.1206)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.260\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.342\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.117\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.117\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.070\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.200\n",
            "Validation Loss: 0.07008431489049043\n",
            "Epoch: [19]  [  0/280]  eta: 0:04:29  lr: 0.000027  loss: 3.7353 (3.7353)  loss_classifier: 0.0145 (0.0145)  loss_box_reg: 0.0308 (0.0308)  loss_keypoint: 3.6633 (3.6633)  loss_objectness: 0.0183 (0.0183)  loss_rpn_box_reg: 0.0084 (0.0084)  time: 0.9642  data: 0.6555  max mem: 2296\n",
            "Epoch: [19]  [279/280]  eta: 0:00:00  lr: 0.000027  loss: 1.8963 (2.0605)  loss_classifier: 0.0192 (0.0215)  loss_box_reg: 0.0291 (0.0382)  loss_keypoint: 1.8540 (1.9915)  loss_objectness: 0.0010 (0.0049)  loss_rpn_box_reg: 0.0022 (0.0045)  time: 0.7693  data: 0.4634  max mem: 2296\n",
            "Epoch: [19] Total time: 0:03:36 (0.7723 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:56  model_time: 0.1659 (0.1659)  evaluator_time: 0.0019 (0.0019)  time: 0.9361  data: 0.7367  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1181 (0.1205)  evaluator_time: 0.0023 (0.0022)  time: 0.8862  data: 0.7328  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8982 s / it)\n",
            "Averaged stats: model_time: 0.1181 (0.1205)  evaluator_time: 0.0023 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.167\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.370\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.132\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.083\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.205\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.205\n",
            "Validation Loss: 0.08266133065378893\n",
            "Epoch: [20]  [  0/280]  eta: 0:04:19  lr: 0.000008  loss: 2.0414 (2.0414)  loss_classifier: 0.0131 (0.0131)  loss_box_reg: 0.0334 (0.0334)  loss_keypoint: 1.9903 (1.9903)  loss_objectness: 0.0013 (0.0013)  loss_rpn_box_reg: 0.0034 (0.0034)  time: 0.9283  data: 0.6602  max mem: 2296\n",
            "Epoch: [20]  [279/280]  eta: 0:00:00  lr: 0.000008  loss: 1.8437 (2.0321)  loss_classifier: 0.0229 (0.0222)  loss_box_reg: 0.0499 (0.0385)  loss_keypoint: 1.7300 (1.9622)  loss_objectness: 0.0022 (0.0051)  loss_rpn_box_reg: 0.0029 (0.0040)  time: 0.7778  data: 0.4706  max mem: 2296\n",
            "Epoch: [20] Total time: 0:03:36 (0.7730 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:50  model_time: 0.1693 (0.1693)  evaluator_time: 0.0020 (0.0020)  time: 0.8434  data: 0.6414  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1178 (0.1211)  evaluator_time: 0.0022 (0.0021)  time: 0.9007  data: 0.7483  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8915 s / it)\n",
            "Averaged stats: model_time: 0.1178 (0.1211)  evaluator_time: 0.0022 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.302\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.092\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.092\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.055\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.160\n",
            "Validation Loss: 0.05513051305130513\n",
            "Epoch: [21]  [  0/280]  eta: 0:07:16  lr: 0.000008  loss: 2.4900 (2.4900)  loss_classifier: 0.0140 (0.0140)  loss_box_reg: 0.0234 (0.0234)  loss_keypoint: 2.4411 (2.4411)  loss_objectness: 0.0075 (0.0075)  loss_rpn_box_reg: 0.0041 (0.0041)  time: 1.5606  data: 1.2155  max mem: 2296\n",
            "Epoch: [21]  [279/280]  eta: 0:00:00  lr: 0.000008  loss: 2.0298 (2.0343)  loss_classifier: 0.0191 (0.0214)  loss_box_reg: 0.0419 (0.0384)  loss_keypoint: 1.9276 (1.9649)  loss_objectness: 0.0013 (0.0052)  loss_rpn_box_reg: 0.0031 (0.0045)  time: 0.7735  data: 0.4604  max mem: 2296\n",
            "Epoch: [21] Total time: 0:03:36 (0.7742 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:56  model_time: 0.1660 (0.1660)  evaluator_time: 0.0019 (0.0019)  time: 0.9456  data: 0.7460  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1187 (0.1208)  evaluator_time: 0.0021 (0.0021)  time: 0.8809  data: 0.7288  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8902 s / it)\n",
            "Averaged stats: model_time: 0.1187 (0.1208)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.308\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.110\n",
            "Validation Loss: 0.03178296401068678\n",
            "Epoch: [22]  [  0/280]  eta: 0:04:31  lr: 0.000008  loss: 1.4422 (1.4422)  loss_classifier: 0.0205 (0.0205)  loss_box_reg: 0.0491 (0.0491)  loss_keypoint: 1.3707 (1.3707)  loss_objectness: 0.0001 (0.0001)  loss_rpn_box_reg: 0.0019 (0.0019)  time: 0.9683  data: 0.6501  max mem: 2296\n",
            "Epoch: [22]  [279/280]  eta: 0:00:00  lr: 0.000008  loss: 1.7697 (2.0006)  loss_classifier: 0.0194 (0.0205)  loss_box_reg: 0.0359 (0.0376)  loss_keypoint: 1.6996 (1.9326)  loss_objectness: 0.0022 (0.0052)  loss_rpn_box_reg: 0.0028 (0.0046)  time: 0.7575  data: 0.4446  max mem: 2296\n",
            "Epoch: [22] Total time: 0:03:33 (0.7608 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:49  model_time: 0.1589 (0.1589)  evaluator_time: 0.0020 (0.0020)  time: 0.8281  data: 0.6359  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1176 (0.1203)  evaluator_time: 0.0021 (0.0021)  time: 0.8729  data: 0.7213  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8837 s / it)\n",
            "Averaged stats: model_time: 0.1176 (0.1203)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.127\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.108\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.105\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.188\n",
            "Validation Loss: 0.06445477730761787\n",
            "Epoch: [23]  [  0/280]  eta: 0:07:47  lr: 0.000008  loss: 2.2187 (2.2187)  loss_classifier: 0.0308 (0.0308)  loss_box_reg: 0.0616 (0.0616)  loss_keypoint: 2.1202 (2.1202)  loss_objectness: 0.0017 (0.0017)  loss_rpn_box_reg: 0.0043 (0.0043)  time: 1.6703  data: 1.2543  max mem: 2296\n",
            "Epoch: [23]  [279/280]  eta: 0:00:00  lr: 0.000008  loss: 1.8072 (2.0187)  loss_classifier: 0.0178 (0.0208)  loss_box_reg: 0.0314 (0.0373)  loss_keypoint: 1.7508 (1.9512)  loss_objectness: 0.0042 (0.0049)  loss_rpn_box_reg: 0.0026 (0.0045)  time: 0.7702  data: 0.4598  max mem: 2296\n",
            "Epoch: [23] Total time: 0:03:37 (0.7765 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:56  model_time: 0.1660 (0.1660)  evaluator_time: 0.0017 (0.0017)  time: 0.9351  data: 0.7359  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1161 (0.1187)  evaluator_time: 0.0021 (0.0021)  time: 0.9048  data: 0.7543  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9011 s / it)\n",
            "Averaged stats: model_time: 0.1161 (0.1187)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.195\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.015\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.090\n",
            "Validation Loss: 0.015002517200872627\n",
            "Epoch: [24]  [  0/280]  eta: 0:04:40  lr: 0.000008  loss: 2.2733 (2.2733)  loss_classifier: 0.0156 (0.0156)  loss_box_reg: 0.0270 (0.0270)  loss_keypoint: 2.2265 (2.2265)  loss_objectness: 0.0015 (0.0015)  loss_rpn_box_reg: 0.0028 (0.0028)  time: 1.0021  data: 0.6726  max mem: 2296\n",
            "Epoch: [24]  [279/280]  eta: 0:00:00  lr: 0.000008  loss: 1.7661 (2.0332)  loss_classifier: 0.0176 (0.0219)  loss_box_reg: 0.0357 (0.0375)  loss_keypoint: 1.7236 (1.9645)  loss_objectness: 0.0021 (0.0047)  loss_rpn_box_reg: 0.0025 (0.0047)  time: 0.7629  data: 0.4548  max mem: 2296\n",
            "Epoch: [24] Total time: 0:03:36 (0.7744 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:57  model_time: 0.1647 (0.1647)  evaluator_time: 0.0017 (0.0017)  time: 0.9577  data: 0.7602  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1181 (0.1207)  evaluator_time: 0.0021 (0.0021)  time: 0.8824  data: 0.7303  max mem: 2296\n",
            "Test: Total time: 0:00:52 (0.8784 s / it)\n",
            "Averaged stats: model_time: 0.1181 (0.1207)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.249\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.124\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.328\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.180\n",
            "Validation Loss: 0.06719046971803554\n",
            "Epoch: [25]  [  0/280]  eta: 0:04:01  lr: 0.000002  loss: 1.9846 (1.9846)  loss_classifier: 0.0201 (0.0201)  loss_box_reg: 0.0304 (0.0304)  loss_keypoint: 1.9060 (1.9060)  loss_objectness: 0.0229 (0.0229)  loss_rpn_box_reg: 0.0052 (0.0052)  time: 0.8631  data: 0.5130  max mem: 2296\n",
            "Epoch: [25]  [279/280]  eta: 0:00:00  lr: 0.000002  loss: 1.7828 (2.0196)  loss_classifier: 0.0156 (0.0222)  loss_box_reg: 0.0365 (0.0402)  loss_keypoint: 1.6987 (1.9472)  loss_objectness: 0.0023 (0.0055)  loss_rpn_box_reg: 0.0027 (0.0044)  time: 0.8051  data: 0.4783  max mem: 2296\n",
            "Epoch: [25] Total time: 0:03:35 (0.7705 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:59  model_time: 0.1683 (0.1683)  evaluator_time: 0.0021 (0.0021)  time: 0.9889  data: 0.7867  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1185 (0.1211)  evaluator_time: 0.0021 (0.0021)  time: 0.9142  data: 0.7610  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9142 s / it)\n",
            "Averaged stats: model_time: 0.1185 (0.1211)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.152\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.051\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.160\n",
            "Validation Loss: 0.050944331721307724\n",
            "Epoch: [26]  [  0/280]  eta: 0:04:08  lr: 0.000002  loss: 1.9571 (1.9571)  loss_classifier: 0.0198 (0.0198)  loss_box_reg: 0.0342 (0.0342)  loss_keypoint: 1.8985 (1.8985)  loss_objectness: 0.0006 (0.0006)  loss_rpn_box_reg: 0.0039 (0.0039)  time: 0.8863  data: 0.6014  max mem: 2296\n",
            "Epoch: [26]  [279/280]  eta: 0:00:00  lr: 0.000002  loss: 1.7717 (2.0042)  loss_classifier: 0.0140 (0.0216)  loss_box_reg: 0.0296 (0.0383)  loss_keypoint: 1.6836 (1.9352)  loss_objectness: 0.0015 (0.0048)  loss_rpn_box_reg: 0.0022 (0.0043)  time: 0.7803  data: 0.4613  max mem: 2296\n",
            "Epoch: [26] Total time: 0:03:36 (0.7735 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:57  model_time: 0.1512 (0.1512)  evaluator_time: 0.0018 (0.0018)  time: 0.9589  data: 0.7748  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1177 (0.1205)  evaluator_time: 0.0021 (0.0021)  time: 0.8904  data: 0.7378  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9001 s / it)\n",
            "Averaged stats: model_time: 0.1177 (0.1205)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.314\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.168\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.162\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.150\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.150\n",
            "Validation Loss: 0.06680336705860154\n",
            "Epoch: [27]  [  0/280]  eta: 0:04:57  lr: 0.000002  loss: 1.8585 (1.8585)  loss_classifier: 0.0199 (0.0199)  loss_box_reg: 0.0402 (0.0402)  loss_keypoint: 1.7841 (1.7841)  loss_objectness: 0.0029 (0.0029)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 1.0631  data: 0.7109  max mem: 2296\n",
            "Epoch: [27]  [279/280]  eta: 0:00:00  lr: 0.000002  loss: 2.0317 (2.0032)  loss_classifier: 0.0211 (0.0219)  loss_box_reg: 0.0324 (0.0389)  loss_keypoint: 1.9451 (1.9330)  loss_objectness: 0.0022 (0.0050)  loss_rpn_box_reg: 0.0030 (0.0044)  time: 0.7842  data: 0.4741  max mem: 2296\n",
            "Epoch: [27] Total time: 0:03:35 (0.7711 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:49  model_time: 0.1567 (0.1567)  evaluator_time: 0.0019 (0.0019)  time: 0.8277  data: 0.6370  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1173 (0.1202)  evaluator_time: 0.0021 (0.0022)  time: 0.8826  data: 0.7307  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9003 s / it)\n",
            "Averaged stats: model_time: 0.1173 (0.1202)  evaluator_time: 0.0021 (0.0022)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.195\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.277\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.140\n",
            "Validation Loss: 0.03718450059143988\n",
            "Epoch: [28]  [  0/280]  eta: 0:04:30  lr: 0.000002  loss: 2.1132 (2.1132)  loss_classifier: 0.0348 (0.0348)  loss_box_reg: 0.0519 (0.0519)  loss_keypoint: 2.0160 (2.0160)  loss_objectness: 0.0047 (0.0047)  loss_rpn_box_reg: 0.0058 (0.0058)  time: 0.9673  data: 0.6109  max mem: 2296\n",
            "Epoch: [28]  [279/280]  eta: 0:00:00  lr: 0.000002  loss: 1.7382 (2.0054)  loss_classifier: 0.0190 (0.0219)  loss_box_reg: 0.0282 (0.0382)  loss_keypoint: 1.6376 (1.9363)  loss_objectness: 0.0007 (0.0050)  loss_rpn_box_reg: 0.0028 (0.0040)  time: 0.7747  data: 0.4636  max mem: 2296\n",
            "Epoch: [28] Total time: 0:03:38 (0.7802 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:57  model_time: 0.1615 (0.1615)  evaluator_time: 0.0017 (0.0017)  time: 0.9631  data: 0.7687  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1174 (0.1200)  evaluator_time: 0.0021 (0.0021)  time: 0.8901  data: 0.7383  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8851 s / it)\n",
            "Averaged stats: model_time: 0.1174 (0.1200)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.079\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.042\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.142\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.250\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.142\n",
            "Validation Loss: 0.04202802038138938\n",
            "Epoch: [29]  [  0/280]  eta: 0:04:27  lr: 0.000002  loss: 2.6630 (2.6630)  loss_classifier: 0.0208 (0.0208)  loss_box_reg: 0.0170 (0.0170)  loss_keypoint: 2.6119 (2.6119)  loss_objectness: 0.0113 (0.0113)  loss_rpn_box_reg: 0.0020 (0.0020)  time: 0.9559  data: 0.6666  max mem: 2296\n",
            "Epoch: [29]  [279/280]  eta: 0:00:00  lr: 0.000002  loss: 1.6518 (1.9746)  loss_classifier: 0.0201 (0.0211)  loss_box_reg: 0.0403 (0.0382)  loss_keypoint: 1.5904 (1.9053)  loss_objectness: 0.0016 (0.0054)  loss_rpn_box_reg: 0.0034 (0.0045)  time: 0.7812  data: 0.4650  max mem: 2296\n",
            "Epoch: [29] Total time: 0:03:35 (0.7695 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:50  model_time: 0.1676 (0.1676)  evaluator_time: 0.0019 (0.0019)  time: 0.8402  data: 0.6387  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1165 (0.1198)  evaluator_time: 0.0021 (0.0021)  time: 0.8841  data: 0.7332  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8886 s / it)\n",
            "Averaged stats: model_time: 0.1165 (0.1198)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.081\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.130\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.217\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.130\n",
            "Validation Loss: 0.03677829717083925\n",
            "Epoch: [30]  [  0/280]  eta: 0:05:09  lr: 0.000001  loss: 1.5534 (1.5534)  loss_classifier: 0.0303 (0.0303)  loss_box_reg: 0.0303 (0.0303)  loss_keypoint: 1.4848 (1.4848)  loss_objectness: 0.0014 (0.0014)  loss_rpn_box_reg: 0.0067 (0.0067)  time: 1.1053  data: 0.7462  max mem: 2296\n",
            "Epoch: [30]  [279/280]  eta: 0:00:00  lr: 0.000001  loss: 2.1248 (1.9934)  loss_classifier: 0.0221 (0.0214)  loss_box_reg: 0.0408 (0.0382)  loss_keypoint: 1.9923 (1.9236)  loss_objectness: 0.0018 (0.0056)  loss_rpn_box_reg: 0.0030 (0.0046)  time: 0.7829  data: 0.4701  max mem: 2296\n",
            "Epoch: [30] Total time: 0:03:36 (0.7742 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:50  model_time: 0.1720 (0.1720)  evaluator_time: 0.0020 (0.0020)  time: 0.8437  data: 0.6384  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1166 (0.1210)  evaluator_time: 0.0021 (0.0021)  time: 0.9093  data: 0.7576  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9069 s / it)\n",
            "Averaged stats: model_time: 0.1166 (0.1210)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.050\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.160\n",
            "Validation Loss: 0.05015097254406292\n",
            "Epoch: [31]  [  0/280]  eta: 0:06:57  lr: 0.000001  loss: 1.6637 (1.6637)  loss_classifier: 0.0231 (0.0231)  loss_box_reg: 0.0214 (0.0214)  loss_keypoint: 1.6082 (1.6082)  loss_objectness: 0.0035 (0.0035)  loss_rpn_box_reg: 0.0075 (0.0075)  time: 1.4922  data: 1.1187  max mem: 2296\n",
            "Epoch: [31]  [279/280]  eta: 0:00:00  lr: 0.000001  loss: 1.6993 (1.9602)  loss_classifier: 0.0176 (0.0208)  loss_box_reg: 0.0293 (0.0383)  loss_keypoint: 1.6467 (1.8922)  loss_objectness: 0.0010 (0.0048)  loss_rpn_box_reg: 0.0026 (0.0041)  time: 0.7694  data: 0.4730  max mem: 2296\n",
            "Epoch: [31] Total time: 0:03:37 (0.7759 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:01:01  model_time: 0.1677 (0.1677)  evaluator_time: 0.0020 (0.0020)  time: 1.0207  data: 0.8194  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1172 (0.1206)  evaluator_time: 0.0021 (0.0021)  time: 0.9090  data: 0.7571  max mem: 2296\n",
            "Test: Total time: 0:00:54 (0.9059 s / it)\n",
            "Averaged stats: model_time: 0.1172 (0.1206)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.144\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.019\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.032\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.100\n",
            "Validation Loss: 0.019071192833569076\n",
            "Epoch: [32]  [  0/280]  eta: 0:04:34  lr: 0.000001  loss: 1.9424 (1.9424)  loss_classifier: 0.0136 (0.0136)  loss_box_reg: 0.0228 (0.0228)  loss_keypoint: 1.9012 (1.9012)  loss_objectness: 0.0006 (0.0006)  loss_rpn_box_reg: 0.0042 (0.0042)  time: 0.9809  data: 0.6588  max mem: 2296\n",
            "Epoch: [32]  [279/280]  eta: 0:00:00  lr: 0.000001  loss: 1.8703 (1.9629)  loss_classifier: 0.0212 (0.0215)  loss_box_reg: 0.0359 (0.0380)  loss_keypoint: 1.7785 (1.8940)  loss_objectness: 0.0012 (0.0050)  loss_rpn_box_reg: 0.0033 (0.0044)  time: 0.7608  data: 0.4486  max mem: 2296\n",
            "Epoch: [32] Total time: 0:03:39 (0.7827 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:50  model_time: 0.1689 (0.1689)  evaluator_time: 0.0019 (0.0019)  time: 0.8358  data: 0.6337  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1184 (0.1202)  evaluator_time: 0.0020 (0.0021)  time: 0.8955  data: 0.7426  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8976 s / it)\n",
            "Averaged stats: model_time: 0.1184 (0.1202)  evaluator_time: 0.0020 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.467\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.285\n",
            "Validation Loss: 0.1613126366412459\n",
            "Epoch: [33]  [  0/280]  eta: 0:04:33  lr: 0.000001  loss: 1.8569 (1.8569)  loss_classifier: 0.0150 (0.0150)  loss_box_reg: 0.0248 (0.0248)  loss_keypoint: 1.8151 (1.8151)  loss_objectness: 0.0004 (0.0004)  loss_rpn_box_reg: 0.0016 (0.0016)  time: 0.9750  data: 0.6465  max mem: 2296\n",
            "Epoch: [33]  [279/280]  eta: 0:00:00  lr: 0.000001  loss: 2.0430 (1.9741)  loss_classifier: 0.0173 (0.0215)  loss_box_reg: 0.0384 (0.0390)  loss_keypoint: 1.9431 (1.9039)  loss_objectness: 0.0022 (0.0051)  loss_rpn_box_reg: 0.0032 (0.0046)  time: 0.7871  data: 0.4707  max mem: 2296\n",
            "Epoch: [33] Total time: 0:03:37 (0.7775 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:51  model_time: 0.1691 (0.1691)  evaluator_time: 0.0019 (0.0019)  time: 0.8556  data: 0.6531  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1181 (0.1175)  evaluator_time: 0.0022 (0.0021)  time: 0.9077  data: 0.7557  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8927 s / it)\n",
            "Averaged stats: model_time: 0.1181 (0.1175)  evaluator_time: 0.0022 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.283\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.178\n",
            "Validation Loss: 0.06818510546706844\n",
            "Epoch: [34]  [  0/280]  eta: 0:04:00  lr: 0.000001  loss: 1.5919 (1.5919)  loss_classifier: 0.0167 (0.0167)  loss_box_reg: 0.0254 (0.0254)  loss_keypoint: 1.5444 (1.5444)  loss_objectness: 0.0005 (0.0005)  loss_rpn_box_reg: 0.0050 (0.0050)  time: 0.8586  data: 0.5536  max mem: 2296\n",
            "Epoch: [34]  [279/280]  eta: 0:00:00  lr: 0.000001  loss: 2.0782 (1.9908)  loss_classifier: 0.0172 (0.0211)  loss_box_reg: 0.0366 (0.0373)  loss_keypoint: 2.0137 (1.9237)  loss_objectness: 0.0014 (0.0044)  loss_rpn_box_reg: 0.0034 (0.0043)  time: 0.7619  data: 0.4549  max mem: 2296\n",
            "Epoch: [34] Total time: 0:03:35 (0.7694 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:58  model_time: 0.1550 (0.1550)  evaluator_time: 0.0018 (0.0018)  time: 0.9774  data: 0.7890  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1165 (0.1171)  evaluator_time: 0.0021 (0.0021)  time: 0.8834  data: 0.7324  max mem: 2296\n",
            "Test: Total time: 0:00:52 (0.8776 s / it)\n",
            "Averaged stats: model_time: 0.1165 (0.1171)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.167\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.107\n",
            "Validation Loss: 0.025925955498775684\n",
            "Epoch: [35]  [  0/280]  eta: 0:04:42  lr: 0.000000  loss: 2.2958 (2.2958)  loss_classifier: 0.0157 (0.0157)  loss_box_reg: 0.0304 (0.0304)  loss_keypoint: 2.2440 (2.2440)  loss_objectness: 0.0045 (0.0045)  loss_rpn_box_reg: 0.0012 (0.0012)  time: 1.0076  data: 0.7050  max mem: 2296\n",
            "Epoch: [35]  [279/280]  eta: 0:00:00  lr: 0.000000  loss: 1.7704 (2.0121)  loss_classifier: 0.0167 (0.0216)  loss_box_reg: 0.0341 (0.0383)  loss_keypoint: 1.7142 (1.9423)  loss_objectness: 0.0016 (0.0052)  loss_rpn_box_reg: 0.0029 (0.0047)  time: 0.7816  data: 0.4703  max mem: 2296\n",
            "Epoch: [35] Total time: 0:03:34 (0.7672 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/60]  eta: 0:00:56  model_time: 0.1661 (0.1661)  evaluator_time: 0.0018 (0.0018)  time: 0.9352  data: 0.7363  max mem: 2296\n",
            "Test:  [59/60]  eta: 0:00:00  model_time: 0.1168 (0.1179)  evaluator_time: 0.0021 (0.0021)  time: 0.9073  data: 0.7563  max mem: 2296\n",
            "Test: Total time: 0:00:53 (0.8967 s / it)\n",
            "Averaged stats: model_time: 0.1168 (0.1179)  evaluator_time: 0.0021 (0.0021)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.143\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
            "IoU metric: keypoints\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.027\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.027\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.110\n",
            "Validation Loss: 0.02724924666379682\n",
            "Epoch: [36]  [  0/280]  eta: 0:04:39  lr: 0.000000  loss: 1.3793 (1.3793)  loss_classifier: 0.0139 (0.0139)  loss_box_reg: 0.0374 (0.0374)  loss_keypoint: 1.3166 (1.3166)  loss_objectness: 0.0063 (0.0063)  loss_rpn_box_reg: 0.0051 (0.0051)  time: 0.9991  data: 0.6747  max mem: 2296\n",
            "Epoch: [36]  [279/280]  eta: 0:00:00  lr: 0.000000  loss: 1.8508 (1.9938)  loss_classifier: 0.0188 (0.0220)  loss_box_reg: 0.0326 (0.0379)  loss_keypoint: 1.7268 (1.9247)  loss_objectness: 0.0022 (0.0046)  loss_rpn_box_reg: 0.0031 (0.0046)  time: 0.7855  data: 0.4768  max mem: 2296\n",
            "Epoch: [36] Total time: 0:03:36 (0.7729 s / it)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)\n",
        "KEYPOINTS_FOLDER_TRAIN = '/content/drive/MyDrive/TennisMLProject'\n",
        "#KEYPOINTS_FOLDER_TEST = '/content/drive/MyDrive/TennisMLProject'\n",
        "\n",
        "#dataset_train = ClassDataset(KEYPOINTS_FOLDER_TRAIN, transform=train_transform(), demo=False)\n",
        "#dataset_test = ClassDataset(KEYPOINTS_FOLDER_TEST, transform=None, demo=False)\n",
        "\n",
        "#data_loader_train = DataLoader(dataset_train, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "#data_loader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "model = get_model(num_keypoints = 5)\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.3)\n",
        "num_epochs = 100\n",
        "\n",
        "best_val = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=1000)\n",
        "    lr_scheduler.step()\n",
        "    #print(evaluate.__module__)\n",
        "    model.eval()\n",
        "    val_stats = evaluate(model, val_loader, device)\n",
        "    val_loss = val_stats.coco_eval[\"keypoints\"].stats[0]\n",
        "    print(\"Validation Loss: \"+str(val_loss))\n",
        "    if val_loss >= best_val:\n",
        "      # Save model weights after training\n",
        "      torch.save(model.state_dict(), '/content/drive/MyDrive/BestTennisModel.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXHr2tEqnVvy"
      },
      "outputs": [],
      "source": [
        "model = get_model(num_keypoints = 5)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/BestTennisModel.pth'))\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "test_stats = evaluate(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the correct device and set it to evaluation mode before the loop\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Initialize the data loader iterator\n",
        "iterator = iter(data_loader_test)\n",
        "\n",
        "# Fetch the next batch of images and targets\n",
        "images, targets = next(iterator)\n",
        "\n",
        "# Convert list of images to the appropriate device\n",
        "images = [image.to(device) for image in images]\n",
        "\n",
        "# No need to call model.to(device) and model.eval() again since it's already set before\n",
        "with torch.no_grad():\n",
        "    # Perform inference\n",
        "    output = model(images)\n",
        "\n",
        "# Print predictions for the current batch\n",
        "print(\"Predictions:\\n\", output)"
      ],
      "metadata": {
        "id": "62oMHu8FTfmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure images and output are moved to CPU and detach from the graph for post-processing\n",
        "image = images[0].permute(1, 2, 0).detach().cpu().numpy() * 255\n",
        "image = image.astype(np.uint8)\n",
        "scores = output[0]['scores'].detach().cpu().numpy()\n",
        "\n",
        "# Filter detections with scores higher than 0.7\n",
        "high_scores_idxs = np.where(scores > 0.7)[0]\n",
        "\n",
        "# Apply Non-Maximum Suppression (NMS) for the high scoring boxes\n",
        "post_nms_idxs = torchvision.ops.nms(\n",
        "    output[0]['boxes'][high_scores_idxs],\n",
        "    output[0]['scores'][high_scores_idxs],\n",
        "    0.3  # IOU threshold for NMS\n",
        ").cpu().numpy()\n",
        "\n",
        "# Extract keypoints and boxes after applying score threshold and NMS\n",
        "keypoints = [kp[:2].int().tolist() for kp in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy()]\n",
        "bboxes = [bbox.int().tolist() for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy()]\n",
        "\n",
        "# Visualize results\n",
        "visualize(image, bboxes, keypoints)"
      ],
      "metadata": {
        "id": "rLtFTct_UAkf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}